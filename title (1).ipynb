{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YL4ivHiH0KH7",
        "outputId": "57587693-1761-4377-ccf2-a3a080237e05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/176.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m176.0/176.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/803.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m803.2/803.2 kB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m75.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0K\n",
            "added 22 packages in 5s\n",
            "\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0K3 packages are looking for funding\n",
            "\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâœ… Installation complete!\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install -q streamlit opencv-python-headless moviepy yt-dlp openai-whisper\n",
        "!pip install -q transformers datasets scikit-learn librosa accelerate\n",
        "!pip install -q plotly\n",
        "\n",
        "# Install localtunnel for public URL\n",
        "!npm install -g localtunnel\n",
        "\n",
        "print(\"âœ… Installation complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVHLgPYK0Mzt",
        "outputId": "c2c66461-d8c5-48e1-db8d-4762e8b8c1e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting chapter_pipeline.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile chapter_pipeline.py\n",
        "# =============================\n",
        "# INSTALLATION (Run once in Kaggle)\n",
        "# =============================\n",
        "# !pip install opencv-python-headless moviepy yt-dlp openai-whisper transformers datasets scikit-learn librosa accelerate\n",
        "\n",
        "# =============================\n",
        "# IMPORTS\n",
        "# =============================\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import whisper\n",
        "from transformers import CLIPProcessor, CLIPModel, pipeline\n",
        "import json\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "import re\n",
        "import yt_dlp\n",
        "import gc\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"âœ… Dependencies loaded!\")\n",
        "\n",
        "# =============================\n",
        "# 1. CACHE CLEARING\n",
        "# =============================\n",
        "def clear_cache():\n",
        "    \"\"\"Clear all cache and memory between runs\"\"\"\n",
        "    print(\"ğŸ§¹ Clearing cache and memory...\")\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.cuda.synchronize()\n",
        "        print(\"âœ… GPU cache cleared\")\n",
        "\n",
        "    gc.collect()\n",
        "    print(\"âœ… Python garbage collected\")\n",
        "\n",
        "    for file in [\"/kaggle/working/downloaded_video.mp4\", \"/kaggle/working/final_chapters.json\"]:\n",
        "        if os.path.exists(file):\n",
        "            os.remove(file)\n",
        "            print(f\"âœ… Removed {file}\")\n",
        "\n",
        "    print(\"ğŸ¯ Cache cleared - ready for fresh processing!\")\n",
        "\n",
        "# =============================\n",
        "# 2. YOUTUBE VIDEO DOWNLOADER\n",
        "# =============================\n",
        "def download_youtube_video(youtube_url, output_path=\"/kaggle/working/downloaded_video.mp4\"):\n",
        "    \"\"\"Download YouTube video with validation\"\"\"\n",
        "    print(\"ğŸ“¥ Downloading YouTube video...\")\n",
        "\n",
        "    ydl_opts = {\n",
        "        'format': 'best[height<=720]',\n",
        "        'outtmpl': output_path,\n",
        "        'quiet': False,\n",
        "        'no_warnings': True\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "            ydl.download([youtube_url])\n",
        "\n",
        "        if os.path.exists(output_path):\n",
        "            file_size = os.path.getsize(output_path) / (1024 * 1024)\n",
        "            print(f\"âœ… Video downloaded: {file_size:.1f} MB\")\n",
        "            return output_path\n",
        "        else:\n",
        "            print(\"âŒ Download failed - file not found\")\n",
        "            return None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Download error: {e}\")\n",
        "        return None\n",
        "\n",
        "# =============================\n",
        "# 3. MODEL LOADING (FIXED DEVICE HANDLING)\n",
        "# =============================\n",
        "def load_models():\n",
        "    \"\"\"Load all AI models with proper device assignment\"\"\"\n",
        "    print(\"ğŸ”¹ Loading AI Models...\")\n",
        "\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    device_id = 0 if device == \"cuda\" else -1\n",
        "\n",
        "    if device == \"cuda\":\n",
        "        print(f\"ğŸ¯ Using GPU: {torch.cuda.get_device_name()}\")\n",
        "    else:\n",
        "        print(\"âš¡ Using CPU\")\n",
        "\n",
        "    models = {}\n",
        "\n",
        "    try:\n",
        "        # Vision model\n",
        "        print(\"ğŸ–¼ï¸ Loading CLIP...\")\n",
        "        models['clip_model'] = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)\n",
        "        models['clip_processor'] = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "\n",
        "        # Audio transcription\n",
        "        print(\"ğŸ™ï¸ Loading Whisper...\")\n",
        "        models['whisper_model'] = whisper.load_model(\"base\", device=device)\n",
        "\n",
        "        # Text summarization (FIXED: Added device parameter)\n",
        "        print(\"ğŸ“ Loading BART...\")\n",
        "        models['summarizer'] = pipeline(\n",
        "            \"summarization\",\n",
        "            model=\"facebook/bart-large-cnn\",\n",
        "            device=device_id\n",
        "        )\n",
        "\n",
        "        # Emotion analysis (FIXED: Added device parameter)\n",
        "        print(\"ğŸ­ Loading emotion classifier...\")\n",
        "        models['emotion_classifier'] = pipeline(\n",
        "            \"text-classification\",\n",
        "            model=\"j-hartmann/emotion-english-distilroberta-base\",\n",
        "            return_all_scores=True,\n",
        "            device=device_id\n",
        "        )\n",
        "\n",
        "        # Title generation (FIXED: Added device parameter)\n",
        "        print(\"ğŸ·ï¸ Loading advanced title LLM (FLAN-T5-LARGE)...\")\n",
        "        models['title_generator'] = pipeline(\n",
        "                \"text2text-generation\",\n",
        "            model=\"google/flan-t5-large\",\n",
        "            device=device_id\n",
        "        )\n",
        "\n",
        "\n",
        "        models['device'] = device\n",
        "        print(\"âœ… All models loaded successfully!\")\n",
        "        return models\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Model loading failed: {e}\")\n",
        "        return None\n",
        "\n",
        "# =============================\n",
        "# 4. KEYFRAME EXTRACTION (OPTIMIZED)\n",
        "# =============================\n",
        "def extract_key_frames(video_path, clip_processor, clip_model, device, target_frames=60):\n",
        "    \"\"\"Extract meaningful frames with validation\"\"\"\n",
        "    print(\"ğŸ¬ Extracting key frames...\")\n",
        "\n",
        "    if not os.path.exists(video_path):\n",
        "        print(f\"âŒ Video file not found: {video_path}\")\n",
        "        return np.array([]), [], []\n",
        "\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        print(\"âŒ Could not open video\")\n",
        "        return np.array([]), [], []\n",
        "\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    duration = total_frames / fps if fps > 0 else 0\n",
        "\n",
        "    print(f\"ğŸ“¹ Video: {total_frames} frames, {duration:.1f}s, {fps:.1f} FPS\")\n",
        "\n",
        "    if total_frames == 0:\n",
        "        print(\"âŒ No frames in video\")\n",
        "        cap.release()\n",
        "        return np.array([]), [], []\n",
        "\n",
        "    frame_interval = max(10, total_frames // target_frames)\n",
        "    print(f\"ğŸ“Š Sampling every {frame_interval} frames\")\n",
        "\n",
        "    frame_features, frame_indices, frame_timestamps = [], [], []\n",
        "    prev_frame = None\n",
        "    idx = 0\n",
        "    processed = 0\n",
        "\n",
        "    while processed < target_frames and idx < total_frames:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        if idx % frame_interval == 0:\n",
        "            # Skip similar frames\n",
        "            if prev_frame is not None:\n",
        "                diff = cv2.absdiff(prev_frame, frame)\n",
        "                if np.count_nonzero(diff) < 5000:\n",
        "                    idx += 1\n",
        "                    continue\n",
        "\n",
        "            try:\n",
        "                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "                inputs = clip_processor(images=rgb_frame, return_tensors=\"pt\").to(device)\n",
        "                with torch.no_grad():\n",
        "                    feat = clip_model.get_image_features(**inputs)\n",
        "\n",
        "                frame_features.append(feat.cpu().numpy().flatten())\n",
        "                frame_indices.append(idx)\n",
        "                frame_timestamps.append(idx / fps)\n",
        "                prev_frame = frame.copy()\n",
        "                processed += 1\n",
        "\n",
        "                # Clear GPU memory periodically\n",
        "                if processed % 10 == 0 and device == \"cuda\":\n",
        "                    torch.cuda.empty_cache()\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"âš ï¸ Frame processing error at {idx}: {e}\")\n",
        "                continue\n",
        "\n",
        "        idx += 1\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "    print(f\"âœ… Extracted {len(frame_indices)} key frames\")\n",
        "    return np.array(frame_features), frame_indices, frame_timestamps\n",
        "\n",
        "# =============================\n",
        "# 5. SCENE DETECTION (IMPROVED)\n",
        "# =============================\n",
        "def detect_meaningful_scenes(frame_features, frame_timestamps, min_chapter_seconds=45):\n",
        "    \"\"\"Detect natural scene changes with optimal clustering\"\"\"\n",
        "    print(\"ğŸ­ Detecting scene changes...\")\n",
        "\n",
        "    if len(frame_features) < 10:\n",
        "        print(\"âš ï¸ Limited frames, using time-based segmentation\")\n",
        "        total_duration = frame_timestamps[-1] if frame_timestamps else 600\n",
        "        num_chapters = max(3, int(total_duration / 120))\n",
        "        return [int(i * len(frame_features) / num_chapters) for i in range(num_chapters)]\n",
        "\n",
        "    # Find optimal cluster count\n",
        "    best_n_clusters = 3\n",
        "    best_score = -1\n",
        "\n",
        "    for n_clusters in range(3, min(10, len(frame_features) // 5)):\n",
        "        try:\n",
        "            kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
        "            clusters = kmeans.fit_predict(frame_features)\n",
        "\n",
        "            if len(np.unique(clusters)) > 1:\n",
        "                score = silhouette_score(frame_features, clusters)\n",
        "                if score > best_score:\n",
        "                    best_score = score\n",
        "                    best_n_clusters = n_clusters\n",
        "        except Exception:\n",
        "            continue\n",
        "\n",
        "    print(f\"ğŸ“Š Using {best_n_clusters} clusters (silhouette: {best_score:.3f})\")\n",
        "\n",
        "    # Apply clustering\n",
        "    kmeans = KMeans(n_clusters=best_n_clusters, random_state=42, n_init=10)\n",
        "    clusters = kmeans.fit_predict(frame_features)\n",
        "\n",
        "    # Find scene changes\n",
        "    scene_changes = [0]\n",
        "    current_cluster = clusters[0]\n",
        "    last_change_time = frame_timestamps[0]\n",
        "\n",
        "    for i in range(1, len(clusters)):\n",
        "        if clusters[i] != current_cluster:\n",
        "            change_time = frame_timestamps[i]\n",
        "            if change_time - last_change_time >= min_chapter_seconds:\n",
        "                scene_changes.append(i)\n",
        "                current_cluster = clusters[i]\n",
        "                last_change_time = change_time\n",
        "\n",
        "    print(f\"âœ… Detected {len(scene_changes)} scenes\")\n",
        "    return scene_changes\n",
        "\n",
        "# =============================\n",
        "# 6. EMOTION ANALYSIS (TYPE-SAFE)\n",
        "# =============================\n",
        "def analyze_emotion(text, emotion_classifier):\n",
        "    \"\"\"Analyze emotional tone with safe type handling\"\"\"\n",
        "    try:\n",
        "        # Limit text length for efficiency\n",
        "        emotions = emotion_classifier(text[:400])[0]\n",
        "\n",
        "        # Sort by score (handle mixed types)\n",
        "        top_emotions = sorted(\n",
        "            emotions,\n",
        "            key=lambda x: float(x['score']),\n",
        "            reverse=True\n",
        "        )[:2]\n",
        "\n",
        "        result = {\n",
        "            'primary_emotion': str(top_emotions[0]['label']),\n",
        "            'primary_score': float(top_emotions[0]['score']),\n",
        "            'secondary_emotion': str(top_emotions[1]['label']),\n",
        "            'secondary_score': float(top_emotions[1]['score'])\n",
        "        }\n",
        "\n",
        "        return result\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ Emotion analysis failed: {e}\")\n",
        "        return {\n",
        "            'primary_emotion': 'neutral',\n",
        "            'primary_score': 1.0,\n",
        "            'secondary_emotion': 'neutral',\n",
        "            'secondary_score': 0.0\n",
        "        }\n",
        "\n",
        "# =============================\n",
        "# ENHANCED SEMANTIC SUMMARIZATION & TITLE GENERATION\n",
        "# Drop-in replacement for existing functions - NO MODULE NAME CHANGES\n",
        "# =============================\n",
        "\n",
        "import re\n",
        "import torch\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# =============================\n",
        "# PERFECT LLM-BASED TITLE GENERATION & SEMANTIC SUMMARIZATION\n",
        "# Optimized for real-world results with proper LLM prompting\n",
        "# =============================\n",
        "\n",
        "import re\n",
        "import torch\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# =============================\n",
        "# PERFECT TITLE GENERATION WITH LLM\n",
        "# =============================\n",
        "def generate_chapter_title(summary_text, chapter_index=None, emotion_data=None, title_generator=None):\n",
        "    \"\"\"\n",
        "    PERFECTED: LLM-first title generation with robust prompting\n",
        "\n",
        "    Args:\n",
        "        summary_text: Summary to generate title from\n",
        "        chapter_index: Chapter number for variety\n",
        "        emotion_data: Emotion dict with primary_emotion and scores\n",
        "        title_generator: HuggingFace T5/FLAN-T5 model\n",
        "\n",
        "    Returns:\n",
        "        Clean, meaningful 3-6 word title\n",
        "    \"\"\"\n",
        "\n",
        "    # Clean input\n",
        "    clean_summary = ' '.join(summary_text.split())\n",
        "\n",
        "    # =============================\n",
        "    # PRIMARY METHOD: Optimized LLM Generation\n",
        "    # =============================\n",
        "    if title_generator is not None:\n",
        "        try:\n",
        "            # Extract core content (first 150 chars usually has main idea)\n",
        "            core_content = clean_summary[:150].strip()\n",
        "\n",
        "            # Multiple optimized prompts (T5/FLAN-T5 specific)\n",
        "            prompts = [\n",
        "                f\"Generate a short 4-word title: {core_content}\",\n",
        "                f\"Summarize this in 4 words: {core_content}\",\n",
        "                f\"Title for this passage: {core_content}\",\n",
        "                f\"Main topic in 4 words: {core_content}\",\n",
        "                f\"What is this about in 4 words: {core_content}\"\n",
        "            ]\n",
        "\n",
        "            best_title = None\n",
        "            best_score = 0\n",
        "\n",
        "            for prompt in prompts:\n",
        "                try:\n",
        "                    # CRITICAL: T5/FLAN-T5 optimal parameters\n",
        "                    result = title_generator(\n",
        "                        prompt,\n",
        "                        max_new_tokens=20,           # Allow more tokens for flexibility\n",
        "                        min_length=10,               # Ensure minimum output\n",
        "                        do_sample=True,              # Enable sampling for variety\n",
        "                        temperature=0.5,             # Lower = more focused\n",
        "                        top_k=50,                    # Top-k sampling\n",
        "                        top_p=0.85,                  # Nucleus sampling\n",
        "                        repetition_penalty=1.3,      # Prevent word repetition\n",
        "                        num_return_sequences=1,\n",
        "                        early_stopping=True\n",
        "                    )\n",
        "\n",
        "                    raw_title = result[0]['generated_text'].strip()\n",
        "\n",
        "                    # Aggressive cleaning\n",
        "                    cleaned = clean_llm_title(raw_title, prompt)\n",
        "\n",
        "                    # Score quality\n",
        "                    score = score_title_quality(cleaned, clean_summary)\n",
        "\n",
        "                    # Accept if good quality and right length\n",
        "                    word_count = len(cleaned.split())\n",
        "                    if score > best_score and 3 <= word_count <= 7:\n",
        "                        best_score = score\n",
        "                        best_title = cleaned\n",
        "\n",
        "                        # If we found a really good one, stop searching\n",
        "                        if score > 0.6 and 3 <= word_count <= 5:\n",
        "                            break\n",
        "\n",
        "                except Exception as e:\n",
        "                    continue\n",
        "\n",
        "            # Return if we found a good title\n",
        "            if best_title and best_score > 0.4:\n",
        "                print(f\"âœ… LLM Title: '{best_title}' (score: {best_score:.2f})\")\n",
        "                return best_title\n",
        "\n",
        "            # If score too low, try one more time with simpler prompt\n",
        "            if best_score < 0.4:\n",
        "                try:\n",
        "                    simple_prompt = f\"title: {core_content}\"\n",
        "                    result = title_generator(\n",
        "                        simple_prompt,\n",
        "                        max_new_tokens=15,\n",
        "                        temperature=0.4,\n",
        "                        top_p=0.9,\n",
        "                        repetition_penalty=1.2\n",
        "                    )\n",
        "\n",
        "                    raw_title = result[0]['generated_text'].strip()\n",
        "                    cleaned = clean_llm_title(raw_title, simple_prompt)\n",
        "\n",
        "                    if 3 <= len(cleaned.split()) <= 7:\n",
        "                        score = score_title_quality(cleaned, clean_summary)\n",
        "                        if score > 0.3:\n",
        "                            print(f\"âœ… LLM Title (retry): '{cleaned}' (score: {score:.2f})\")\n",
        "                            return cleaned\n",
        "\n",
        "                except Exception:\n",
        "                    pass\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ LLM title generation error: {e}\")\n",
        "\n",
        "    # =============================\n",
        "    # FALLBACK 1: Smart Keyword Extraction\n",
        "    # =============================\n",
        "    try:\n",
        "        title = extract_smart_title(clean_summary)\n",
        "        if title and 3 <= len(title.split()) <= 7:\n",
        "            print(f\"âœ… Keyword Title: '{title}'\")\n",
        "            return title\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ Keyword extraction failed: {e}\")\n",
        "\n",
        "    # =============================\n",
        "    # FALLBACK 2: First Meaningful Phrase\n",
        "    # =============================\n",
        "    try:\n",
        "        title = extract_first_meaningful_phrase(clean_summary)\n",
        "        if title and 3 <= len(title.split()) <= 7:\n",
        "            print(f\"âœ… Phrase Title: '{title}'\")\n",
        "            return title\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ Phrase extraction failed: {e}\")\n",
        "\n",
        "    # =============================\n",
        "    # FALLBACK 3: Context-Aware Emotion Title\n",
        "    # =============================\n",
        "    primary_emotion = 'neutral'\n",
        "    if emotion_data:\n",
        "        try:\n",
        "            if isinstance(emotion_data, dict):\n",
        "                primary_emotion = str(emotion_data.get('primary_emotion', 'neutral')).lower()\n",
        "            else:\n",
        "                primary_emotion = str(emotion_data).lower()\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    title = generate_smart_fallback(clean_summary, primary_emotion, chapter_index)\n",
        "    print(f\"âœ… Fallback Title: '{title}'\")\n",
        "    return title\n",
        "\n",
        "\n",
        "# =============================\n",
        "# AGGRESSIVE LLM OUTPUT CLEANING\n",
        "# =============================\n",
        "def clean_llm_title(raw_title, original_prompt):\n",
        "    \"\"\"Aggressively clean LLM output to get pure title\"\"\"\n",
        "\n",
        "    # Remove the prompt echo (common with T5)\n",
        "    prompt_prefixes = [\n",
        "        'generate a short 4-word title:',\n",
        "        'summarize this in 4 words:',\n",
        "        'title for this passage:',\n",
        "        'main topic in 4 words:',\n",
        "        'what is this about in 4 words:',\n",
        "        'title:',\n",
        "        'summary:',\n",
        "        'chapter title:',\n",
        "        'generate:',\n",
        "        'create:'\n",
        "    ]\n",
        "\n",
        "    cleaned = raw_title.lower()\n",
        "    for prefix in prompt_prefixes:\n",
        "        if cleaned.startswith(prefix):\n",
        "            cleaned = cleaned[len(prefix):].strip()\n",
        "\n",
        "    # Remove common artifacts\n",
        "    cleaned = re.sub(r'^(the |a |an )+', '', cleaned, flags=re.IGNORECASE)\n",
        "    cleaned = re.sub(r'\\s*[:\\-â€“â€”]\\s*', ' ', cleaned)  # Remove colons/dashes\n",
        "    cleaned = cleaned.strip('\"\\'.,!?:;-â€“â€”()[]{}')\n",
        "\n",
        "    # Take only first sentence if multiple\n",
        "    cleaned = re.split(r'[.!?]', cleaned)[0].strip()\n",
        "\n",
        "    # Remove parenthetical content\n",
        "    cleaned = re.sub(r'\\([^)]*\\)|\\[[^\\]]*\\]', '', cleaned)\n",
        "\n",
        "    # Remove numbers at start (chapter numbers)\n",
        "    cleaned = re.sub(r'^\\d+[\\.\\):\\s]+', '', cleaned)\n",
        "\n",
        "    # Remove quotes\n",
        "    cleaned = cleaned.replace('\"', '').replace(\"'\", \"\")\n",
        "\n",
        "    # Normalize whitespace\n",
        "    cleaned = ' '.join(cleaned.split())\n",
        "\n",
        "    # Remove meta words that sneak through\n",
        "    meta_words = ['chapter', 'episode', 'part', 'section', 'introduction', 'conclusion']\n",
        "    words = cleaned.split()\n",
        "    if words and words[0].lower() in meta_words:\n",
        "        words = words[1:]\n",
        "\n",
        "    cleaned = ' '.join(words)\n",
        "\n",
        "    # Proper title case\n",
        "    if cleaned:\n",
        "        words = cleaned.split()\n",
        "        # Words that should stay lowercase (unless first word)\n",
        "        lowercase_words = {'a', 'an', 'the', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by', 'from'}\n",
        "\n",
        "        title_words = []\n",
        "        for i, word in enumerate(words):\n",
        "            if i == 0 or word.lower() not in lowercase_words:\n",
        "                title_words.append(word.capitalize())\n",
        "            else:\n",
        "                title_words.append(word.lower())\n",
        "\n",
        "        cleaned = ' '.join(title_words)\n",
        "\n",
        "    return cleaned\n",
        "\n",
        "\n",
        "# =============================\n",
        "# TITLE QUALITY SCORING\n",
        "# =============================\n",
        "def score_title_quality(title, summary):\n",
        "    \"\"\"Score title quality (0-1 scale)\"\"\"\n",
        "\n",
        "    if not title or len(title.strip()) < 5:\n",
        "        return 0.0\n",
        "\n",
        "    words = title.lower().split()\n",
        "    word_count = len(words)\n",
        "    summary_lower = summary.lower()\n",
        "\n",
        "    score = 0.0\n",
        "\n",
        "    # 1. Length score (prefer 3-5 words) - 25%\n",
        "    if 3 <= word_count <= 5:\n",
        "        score += 0.25\n",
        "    elif word_count == 6 or word_count == 2:\n",
        "        score += 0.15\n",
        "    elif word_count == 7:\n",
        "        score += 0.10\n",
        "\n",
        "    # 2. No bad patterns - 20%\n",
        "    bad_starts = ['write', 'create', 'generate', 'make', 'give', 'provide', 'describe', 'explain', 'tell']\n",
        "    bad_words = ['chapter', 'episode', 'part', 'section', 'video', 'podcast']\n",
        "\n",
        "    if not any(title.lower().startswith(bad) for bad in bad_starts):\n",
        "        score += 0.10\n",
        "\n",
        "    if not any(bad in title.lower() for bad in bad_words):\n",
        "        score += 0.10\n",
        "\n",
        "    # 3. Content relevance - 30%\n",
        "    summary_words = set(summary_lower.split()[:100])\n",
        "    title_words_set = set(words)\n",
        "\n",
        "    # Check how many title words appear in summary\n",
        "    overlap_count = sum(1 for w in title_words_set if w in summary_words)\n",
        "    relevance = overlap_count / len(title_words_set) if title_words_set else 0\n",
        "    score += relevance * 0.30\n",
        "\n",
        "    # 4. Proper nouns and important words - 15%\n",
        "    # Check if title has capitalized words (proper nouns/important concepts)\n",
        "    capital_words = sum(1 for w in title.split() if w[0].isupper())\n",
        "    if capital_words >= 2:\n",
        "        score += 0.15\n",
        "    elif capital_words >= 1:\n",
        "        score += 0.08\n",
        "\n",
        "    # 5. No excessive repetition - 10%\n",
        "    if len(words) == len(set(words)):  # All unique words\n",
        "        score += 0.10\n",
        "\n",
        "    # Penalties\n",
        "    if '?' in title or '!' in title:\n",
        "        score -= 0.1\n",
        "\n",
        "    if any(char.isdigit() for char in title):\n",
        "        score -= 0.05\n",
        "\n",
        "    # Check for gibberish (consecutive consonants)\n",
        "    if re.search(r'[bcdfghjklmnpqrstvwxyz]{5,}', title.lower()):\n",
        "        score -= 0.3\n",
        "\n",
        "    return max(0.0, min(1.0, score))\n",
        "\n",
        "\n",
        "# =============================\n",
        "# SMART KEYWORD EXTRACTION\n",
        "# =============================\n",
        "def extract_smart_title(text):\n",
        "    \"\"\"Extract title using advanced keyword analysis\"\"\"\n",
        "\n",
        "    # Extended stop words\n",
        "    stop_words = {\n",
        "        'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for',\n",
        "        'of', 'with', 'by', 'from', 'as', 'is', 'are', 'was', 'were', 'been',\n",
        "        'be', 'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would',\n",
        "        'could', 'should', 'may', 'might', 'can', 'this', 'that', 'these',\n",
        "        'those', 'it', 'its', 'they', 'them', 'their', 'also', 'very', 'just',\n",
        "        'about', 'into', 'through', 'during', 'before', 'after', 'there',\n",
        "        'here', 'when', 'where', 'why', 'how', 'all', 'each', 'other',\n",
        "        'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so',\n",
        "        'than', 'too', 'can', 'will', 'says', 'said', 'she', 'he'\n",
        "    }\n",
        "\n",
        "    # Extract words (min 3 chars)\n",
        "    words = re.findall(r'\\b[a-zA-Z]{3,}\\b', text)\n",
        "\n",
        "    # Position-weighted frequency\n",
        "    word_scores = {}\n",
        "    for idx, word in enumerate(words[:80]):  # First 80 words\n",
        "        word_lower = word.lower()\n",
        "        if word_lower not in stop_words:\n",
        "            # Earlier position = higher weight\n",
        "            position_weight = 1.5 - (idx / len(words[:80])) * 0.8\n",
        "            # Capitalized words get bonus (likely proper nouns)\n",
        "            cap_bonus = 1.3 if word[0].isupper() and idx > 0 else 1.0\n",
        "\n",
        "            word_scores[word] = word_scores.get(word, 0) + (position_weight * cap_bonus)\n",
        "\n",
        "    # Get top scoring words\n",
        "    sorted_words = sorted(word_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    top_words = [w for w, s in sorted_words[:8]]\n",
        "\n",
        "    # Build title preserving original order\n",
        "    title_words = []\n",
        "    seen = set()\n",
        "\n",
        "    for word in words[:60]:  # Check first 60 words for order\n",
        "        if word in top_words and word.lower() not in seen:\n",
        "            title_words.append(word)\n",
        "            seen.add(word.lower())\n",
        "\n",
        "            if len(title_words) >= 5:\n",
        "                break\n",
        "\n",
        "    if len(title_words) >= 3:\n",
        "        return ' '.join(title_words[:5])\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "# =============================\n",
        "# MEANINGFUL PHRASE EXTRACTION\n",
        "# =============================\n",
        "def extract_first_meaningful_phrase(text):\n",
        "    \"\"\"Extract meaningful phrase from text\"\"\"\n",
        "\n",
        "    # Split into sentences\n",
        "    sentences = re.split(r'[.!?]+', text)\n",
        "\n",
        "    for sent in sentences[:2]:\n",
        "        sent = sent.strip()\n",
        "\n",
        "        # Look for key patterns\n",
        "        patterns = [\n",
        "            r'(?:about|discusses?|covers?|explores?|focuses on)\\s+([A-Z][^.!?]{10,50})',\n",
        "            r'(?:talks? about|explains?|describes?)\\s+([A-Z][^.!?]{10,50})',\n",
        "            r'^([A-Z][^.!?]{15,50})(?:\\s+is|\\s+are|\\s+was|\\s+were)',\n",
        "            r'(?:story|topic|subject|theme)\\s+(?:is|of)\\s+([A-Z][^.!?]{10,50})',\n",
        "        ]\n",
        "\n",
        "        for pattern in patterns:\n",
        "            match = re.search(pattern, sent)\n",
        "            if match:\n",
        "                phrase = match.group(1).strip()\n",
        "                # Clean and validate\n",
        "                phrase = re.sub(r'\\s+', ' ', phrase)\n",
        "                words = phrase.split()\n",
        "\n",
        "                if 3 <= len(words) <= 7:\n",
        "                    return phrase\n",
        "\n",
        "    # Fallback: Take first capitalized sequence\n",
        "    match = re.search(r'\\b([A-Z][a-z]+(?:\\s+[A-Z][a-z]+){1,4})\\b', text)\n",
        "    if match:\n",
        "        phrase = match.group(1)\n",
        "        if 3 <= len(phrase.split()) <= 6:\n",
        "            return phrase\n",
        "\n",
        "    # Last resort: first 4-5 meaningful words\n",
        "    words = text.split()[:15]\n",
        "    stop_words = {'the', 'a', 'an', 'is', 'are', 'was', 'were', 'in', 'on', 'at'}\n",
        "\n",
        "    meaningful = []\n",
        "    for word in words:\n",
        "        if word.lower() not in stop_words or len(meaningful) == 0:\n",
        "            meaningful.append(word)\n",
        "            if len(meaningful) >= 5:\n",
        "                break\n",
        "\n",
        "    if len(meaningful) >= 3:\n",
        "        return ' '.join(meaningful[:5])\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "# =============================\n",
        "# SMART FALLBACK GENERATION\n",
        "# =============================\n",
        "def generate_smart_fallback(text, emotion, chapter_index):\n",
        "    \"\"\"Generate intelligent fallback title using text context\"\"\"\n",
        "\n",
        "    # Try to extract any capitalized proper noun phrase\n",
        "    proper_nouns = re.findall(r'\\b[A-Z][a-z]+(?:\\s+[A-Z][a-z]+){0,2}\\b', text)\n",
        "\n",
        "    if proper_nouns:\n",
        "        # Use first proper noun phrase\n",
        "        phrase = proper_nouns[0]\n",
        "        words = phrase.split()\n",
        "        if 2 <= len(words) <= 5:\n",
        "            return phrase\n",
        "\n",
        "    # Extract first meaningful words\n",
        "    words = text.split()[:30]\n",
        "    stop_words = {'the', 'a', 'an', 'is', 'are', 'was', 'were', 'this', 'that', 'these', 'those'}\n",
        "\n",
        "    meaningful = []\n",
        "    for word in words:\n",
        "        clean_word = re.sub(r'[^a-zA-Z]', '', word)\n",
        "        if clean_word and (len(meaningful) == 0 or clean_word.lower() not in stop_words):\n",
        "            meaningful.append(clean_word)\n",
        "            if len(meaningful) >= 4:\n",
        "                break\n",
        "\n",
        "    if len(meaningful) >= 3:\n",
        "        return ' '.join(w.capitalize() for w in meaningful[:4])\n",
        "\n",
        "    # Last resort: emotion-based with generic but acceptable titles\n",
        "    emotion_titles = {\n",
        "        'joy': ['Positive Moments', 'Uplifting Discussion', 'Encouraging Insights', 'Happy Times'],\n",
        "        'surprise': ['Unexpected Turns', 'Surprising Revelations', 'New Discoveries', 'Fresh Perspectives'],\n",
        "        'neutral': ['Main Discussion', 'Key Points', 'Core Topics', 'Important Insights'],\n",
        "        'anger': ['Critical Issues', 'Serious Discussion', 'Important Concerns', 'Key Challenges'],\n",
        "        'sadness': ['Difficult Topics', 'Challenging Moments', 'Serious Reflection', 'Tough Times'],\n",
        "        'fear': ['Concerning Issues', 'Important Warnings', 'Careful Consideration', 'Critical Points'],\n",
        "        'disgust': ['Problem Areas', 'Critical Flaws', 'Serious Issues', 'Key Problems']\n",
        "    }\n",
        "\n",
        "    title_list = emotion_titles.get(emotion, emotion_titles['neutral'])\n",
        "    idx = chapter_index % len(title_list) if chapter_index is not None else 0\n",
        "    return title_list[idx]\n",
        "\n",
        "\n",
        "# =============================\n",
        "# ENHANCED SEMANTIC SUMMARIZATION\n",
        "# =============================\n",
        "def create_quality_summary(text, summarizer):\n",
        "    \"\"\"\n",
        "    IMPROVED: Multi-strategy semantic summarization\n",
        "\n",
        "    Args:\n",
        "        text: Input text to summarize\n",
        "        summarizer: HuggingFace summarization pipeline\n",
        "\n",
        "    Returns:\n",
        "        High-quality semantic summary\n",
        "    \"\"\"\n",
        "    print(\"ğŸ“ Generating semantic summary...\")\n",
        "\n",
        "    # Clean text\n",
        "    clean_text = ' '.join(text.split())\n",
        "\n",
        "    if len(clean_text) < 50:\n",
        "        return clean_text\n",
        "\n",
        "    # =============================\n",
        "    # STRATEGY 1: Direct abstractive with optimal parameters\n",
        "    # =============================\n",
        "    try:\n",
        "        # Use appropriate length based on input\n",
        "        input_length = len(clean_text.split())\n",
        "\n",
        "        if input_length < 100:\n",
        "            max_len, min_len = 60, 20\n",
        "        elif input_length < 200:\n",
        "            max_len, min_len = 80, 30\n",
        "        else:\n",
        "            max_len, min_len = 100, 35\n",
        "\n",
        "        summary = summarizer(\n",
        "            clean_text[:1000],  # Limit input to prevent errors\n",
        "            max_length=max_len,\n",
        "            min_length=min_len,\n",
        "            length_penalty=2.0,\n",
        "            num_beams=4,\n",
        "            early_stopping=True,\n",
        "            no_repeat_ngram_size=3,\n",
        "            do_sample=False\n",
        "        )[0]['summary_text']\n",
        "\n",
        "        # Validate\n",
        "        if is_valid_summary(summary, clean_text):\n",
        "            print(f\"âœ… Summary generated ({len(summary.split())} words)\")\n",
        "            return summary\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ Direct summarization failed: {e}\")\n",
        "\n",
        "    # =============================\n",
        "    # STRATEGY 2: Extractive fallback\n",
        "    # =============================\n",
        "    try:\n",
        "        key_sentences = extract_key_sentences_simple(clean_text, top_k=2)\n",
        "        if key_sentences and len(key_sentences) >= 1:\n",
        "            summary = ' '.join(key_sentences)\n",
        "\n",
        "            # Try to summarize the extracted sentences\n",
        "            if len(summary.split()) > 40:\n",
        "                try:\n",
        "                    summary = summarizer(\n",
        "                        summary,\n",
        "                        max_length=70,\n",
        "                        min_length=25,\n",
        "                        do_sample=False\n",
        "                    )[0]['summary_text']\n",
        "                except Exception:\n",
        "                    pass\n",
        "\n",
        "            if is_valid_summary(summary, clean_text):\n",
        "                print(f\"âœ… Extractive summary generated\")\n",
        "                return summary\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ Extractive fallback failed: {e}\")\n",
        "\n",
        "    # =============================\n",
        "    # STRATEGY 3: Simple sentence selection\n",
        "    # =============================\n",
        "    sentences = re.split(r'[.!?]+', clean_text)\n",
        "    meaningful = [s.strip() + '.' for s in sentences if len(s.split()) >= 6]\n",
        "\n",
        "    if meaningful:\n",
        "        if len(meaningful) == 1:\n",
        "            return meaningful[0]\n",
        "        elif len(meaningful) >= 2:\n",
        "            summary = ' '.join(meaningful[:2])\n",
        "            return summary\n",
        "\n",
        "    # Absolute fallback\n",
        "    return clean_text[:150] + ('...' if len(clean_text) > 150 else '')\n",
        "\n",
        "\n",
        "def extract_key_sentences_simple(text, top_k=2):\n",
        "    \"\"\"Simple but effective sentence extraction\"\"\"\n",
        "    sentences = re.split(r'[.!?]+', text)\n",
        "    sentences = [s.strip() for s in sentences if len(s.split()) >= 6]\n",
        "\n",
        "    if len(sentences) <= top_k:\n",
        "        return sentences\n",
        "\n",
        "    # Score by position (earlier is better) and length\n",
        "    scored = []\n",
        "    for idx, sent in enumerate(sentences[:10]):  # Only first 10 sentences\n",
        "        position_score = 1.0 / (idx + 1)\n",
        "        length_score = min(1.0, len(sent.split()) / 20)  # Prefer 15-20 words\n",
        "        score = position_score * 0.7 + length_score * 0.3\n",
        "        scored.append((score, idx, sent))\n",
        "\n",
        "    # Get top sentences, maintain original order\n",
        "    scored.sort(reverse=True)\n",
        "    top_indices = sorted([idx for _, idx, _ in scored[:top_k]])\n",
        "\n",
        "    return [sentences[i] for i in top_indices]\n",
        "\n",
        "\n",
        "def is_valid_summary(summary, original_text):\n",
        "    \"\"\"Validate summary quality\"\"\"\n",
        "    if not summary or len(summary) < 20:\n",
        "        return False\n",
        "\n",
        "    words = summary.split()\n",
        "    if len(words) < 8:\n",
        "        return False\n",
        "\n",
        "    # Check for repetition\n",
        "    if len(words) != len(set(words)):\n",
        "        word_counts = Counter(words)\n",
        "        max_repeat = max(word_counts.values())\n",
        "        if max_repeat > len(words) * 0.25:\n",
        "            return False\n",
        "\n",
        "    # Check semantic overlap\n",
        "    summary_words = set(summary.lower().split())\n",
        "    original_words = set(original_text.lower().split()[:100])\n",
        "    overlap = len(summary_words.intersection(original_words))\n",
        "\n",
        "    if overlap < 3:\n",
        "        return False\n",
        "\n",
        "    return True\n",
        "\n",
        "# =============================\n",
        "# 9. CONFIDENCE SCORING\n",
        "# =============================\n",
        "def calculate_confidence_score(chapter_data):\n",
        "    \"\"\"Calculate chapter quality score\"\"\"\n",
        "    score = 0.0\n",
        "\n",
        "    # Summary length (30%)\n",
        "    summary_words = len(chapter_data['summary'].split())\n",
        "    score += 0.3 if summary_words >= 12 else (0.2 if summary_words >= 6 else 0.1)\n",
        "\n",
        "    # Emotion confidence (30%)\n",
        "    score += float(chapter_data['emotion']['primary_score']) * 0.3\n",
        "\n",
        "    # Duration (20%)\n",
        "    duration = chapter_data['duration_seconds']\n",
        "    score += 0.2 if 45 <= duration <= 240 else (0.1 if duration > 20 else 0.0)\n",
        "\n",
        "    # Title quality (20%)\n",
        "    title_words = len(chapter_data['title'].split())\n",
        "    score += 0.2 if 2 <= title_words <= 6 else 0.0\n",
        "\n",
        "    return min(1.0, round(score, 2))\n",
        "# =============================\n",
        "# ADVANCED SEMANTIC TITLE GENERATION (LLM-BASED)\n",
        "# =============================\n",
        "from transformers import pipeline\n",
        "\n",
        "def generate_semantic_title(summary_text, emotion_data=None, chapter_index=None, llm_title_model=None):\n",
        "    \"\"\"\n",
        "    Generate semantically meaningful chapter titles using LLM (FLAN-T5 or GPT fallback)\n",
        "\n",
        "    Args:\n",
        "        summary_text (str): Chapter summary text\n",
        "        emotion_data (dict): Emotion dict (primary_emotion)\n",
        "        chapter_index (int): Chapter number\n",
        "        llm_title_model: Preloaded HuggingFace text2text-generation pipeline\n",
        "\n",
        "    Returns:\n",
        "        str: Semantically meaningful short title\n",
        "    \"\"\"\n",
        "    clean_summary = ' '.join(summary_text.split())\n",
        "    emotion = emotion_data.get(\"primary_emotion\", \"neutral\") if emotion_data else \"neutral\"\n",
        "\n",
        "    if not clean_summary.strip():\n",
        "        return f\"Chapter {chapter_index + 1}\"\n",
        "\n",
        "    # =============================\n",
        "    # 1ï¸âƒ£ PROMPT CONSTRUCTION\n",
        "    # =============================\n",
        "    prompt = (\n",
        "        f\"Generate a short, meaningful title (4â€“8 words) that captures the key theme and emotional tone \"\n",
        "        f\"of the following summary. The emotion is '{emotion}'. \"\n",
        "        f\"Focus on clarity and meaning, avoid generic words like 'chapter' or 'section'.\\n\\n\"\n",
        "        f\"Summary:\\n{clean_summary}\\n\\nTitle:\"\n",
        "    )\n",
        "\n",
        "    # =============================\n",
        "    # 2ï¸âƒ£ TRY LOCAL LLM FIRST (e.g. FLAN-T5-LARGE)\n",
        "    # =============================\n",
        "    try:\n",
        "        if llm_title_model:\n",
        "            result = llm_title_model(\n",
        "                prompt,\n",
        "                max_new_tokens=24,\n",
        "                do_sample=True,\n",
        "                top_p=0.9,\n",
        "                temperature=0.5,\n",
        "                repetition_penalty=1.2,\n",
        "            )[0]['generated_text']\n",
        "\n",
        "            # Clean title output\n",
        "            title = re.split(r'[\\n\\:\\.\\-]', result.strip())[0]\n",
        "            title = re.sub(r'^[Tt]itle\\s*', '', title).strip().title()\n",
        "\n",
        "            if 3 <= len(title.split()) <= 8:\n",
        "                print(f\"ğŸ§  LLM Title Generated: '{title}'\")\n",
        "                return title\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ Local LLM title generation failed: {e}\")\n",
        "\n",
        "    # =============================\n",
        "    # 3ï¸âƒ£ OPTIONAL: GPT FALLBACK (if OpenAI key present)\n",
        "    # =============================\n",
        "    try:\n",
        "        import openai\n",
        "        if os.getenv(\"OPENAI_API_KEY\"):\n",
        "            openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "            response = openai.ChatCompletion.create(\n",
        "                model=\"gpt-3.5-turbo\",\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"You are a concise, creative title generator.\"},\n",
        "                    {\"role\": \"user\", \"content\": prompt}\n",
        "                ],\n",
        "                max_tokens=24,\n",
        "                temperature=0.6,\n",
        "                top_p=0.9\n",
        "            )\n",
        "\n",
        "            title = response['choices'][0]['message']['content'].strip()\n",
        "            title = re.split(r'[\\n\\:\\.\\-]', title)[0].strip().title()\n",
        "\n",
        "            if 3 <= len(title.split()) <= 8:\n",
        "                print(f\"ğŸ’¡ GPT Title: '{title}'\")\n",
        "                return title\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ GPT fallback failed: {e}\")\n",
        "\n",
        "    # =============================\n",
        "    # 4ï¸âƒ£ FALLBACK: Use existing title generator logic\n",
        "    # =============================\n",
        "    try:\n",
        "        return generate_chapter_title(summary_text, chapter_index, emotion_data)\n",
        "    except Exception:\n",
        "        return f\"{emotion.capitalize()} Insights - Part {chapter_index + 1}\"\n",
        "\n",
        "\n",
        "# =============================\n",
        "# 10. MAIN PIPELINE (CORRECTED ORDER)\n",
        "# =============================\n",
        "def process_video_pipeline(youtube_url):\n",
        "    \"\"\"Main processing pipeline with proper order\"\"\"\n",
        "    print(\"ğŸš€ Starting Video Processing Pipeline...\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Download\n",
        "    video_path = download_youtube_video(youtube_url)\n",
        "    if not video_path:\n",
        "        return []\n",
        "\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Load models\n",
        "    models = load_models()\n",
        "    if not models:\n",
        "        return []\n",
        "\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Extract features\n",
        "    frame_features, frame_indices, frame_timestamps = extract_key_frames(\n",
        "        video_path, models['clip_processor'], models['clip_model'],\n",
        "        models['device'], target_frames=60\n",
        "    )\n",
        "\n",
        "    # Get video metadata\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    video_duration = total_frames / fps if fps > 0 else 0\n",
        "    cap.release()\n",
        "\n",
        "    if len(frame_features) == 0:\n",
        "        print(\"âš ï¸ No features, using fallback segmentation\")\n",
        "        scene_times = [0, video_duration * 0.25, video_duration * 0.5,\n",
        "                      video_duration * 0.75, video_duration]\n",
        "    else:\n",
        "        scene_indices = detect_meaningful_scenes(frame_features, frame_timestamps)\n",
        "        scene_times = [frame_timestamps[i] for i in scene_indices]\n",
        "        scene_times.append(video_duration)\n",
        "\n",
        "    print(f\"â±ï¸ Video duration: {video_duration:.1f}s\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Transcribe\n",
        "    print(\"ğŸ™ï¸ Transcribing audio...\")\n",
        "    try:\n",
        "        transcript_result = models['whisper_model'].transcribe(video_path)\n",
        "        full_transcript = transcript_result[\"text\"]\n",
        "        print(f\"âœ… Transcript: {len(full_transcript)} chars\")\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Transcription failed: {e}\")\n",
        "        return []\n",
        "\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Generate chapters\n",
        "    print(\"ğŸ“š Generating chapters...\")\n",
        "    chapters = []\n",
        "    words = full_transcript.split()\n",
        "    words_per_second = len(words) / video_duration if video_duration > 0 else 2\n",
        "\n",
        "    for i in range(len(scene_times) - 1):\n",
        "        start_time = scene_times[i]\n",
        "        end_time = scene_times[i + 1]\n",
        "        duration = end_time - start_time\n",
        "\n",
        "        if duration < 20:\n",
        "            continue\n",
        "\n",
        "        start_word_idx = max(0, min(int(start_time * words_per_second), len(words) - 1))\n",
        "        end_word_idx = min(len(words), int(end_time * words_per_second))\n",
        "\n",
        "        word_count = end_word_idx - start_word_idx\n",
        "        if word_count < 10:\n",
        "            continue\n",
        "\n",
        "        chapter_text = \" \".join(words[start_word_idx:end_word_idx])\n",
        "\n",
        "        print(f\"\\nğŸ“– Chapter {len(chapters) + 1}:\")\n",
        "        print(f\"   â° {int(start_time)}s - {int(end_time)}s ({int(duration)}s)\")\n",
        "\n",
        "        # CORRECTED ORDER: Summary â†’ Emotion â†’ Title\n",
        "        summary = create_quality_summary(chapter_text, models['summarizer'])\n",
        "        emotion_data = analyze_emotion(chapter_text, models['emotion_classifier'])\n",
        "        title = generate_semantic_title(\n",
        "          summary_text=summary,\n",
        "          emotion_data=emotion_data,\n",
        "          chapter_index=len(chapters),\n",
        "          llm_title_model=models['title_generator']\n",
        "      )\n",
        "\n",
        "\n",
        "        chapter = {\n",
        "            \"chapter_number\": len(chapters) + 1,\n",
        "            \"title\": title,\n",
        "            \"start_time\": int(start_time),\n",
        "            \"end_time\": int(end_time),\n",
        "            \"duration_seconds\": int(duration),\n",
        "            \"start_word\": start_word_idx,\n",
        "            \"end_word\": end_word_idx,\n",
        "            \"summary\": summary,\n",
        "            \"emotion\": emotion_data,\n",
        "            \"word_count\": word_count\n",
        "        }\n",
        "\n",
        "        chapter[\"confidence_score\"] = calculate_confidence_score(chapter)\n",
        "        chapters.append(chapter)\n",
        "\n",
        "        print(f\"   âœ… Confidence: {chapter['confidence_score']:.0%}\")\n",
        "\n",
        "        # Clear memory\n",
        "        if len(chapters) % 3 == 0 and models['device'] == \"cuda\":\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    print(\"=\" * 50)\n",
        "    print(f\"ğŸ‰ Generated {len(chapters)} chapters\")\n",
        "    return chapters\n",
        "\n",
        "# =============================\n",
        "# 11. SAVE AND DISPLAY\n",
        "# =============================\n",
        "def save_and_display_results(chapters):\n",
        "    \"\"\"Save and display results\"\"\"\n",
        "    output_file = \"/kaggle/working/final_chapters.json\"\n",
        "\n",
        "    with open(output_file, \"w\", encoding='utf-8') as f:\n",
        "        json.dump(chapters, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    print(f\"\\nğŸ’¾ Saved to: {output_file}\")\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"ğŸ“‹ FINAL CHAPTERS\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    if not chapters:\n",
        "        print(\"âš ï¸ No chapters generated\")\n",
        "        return\n",
        "\n",
        "    total_duration = sum(ch['duration_seconds'] for ch in chapters)\n",
        "    avg_confidence = sum(ch['confidence_score'] for ch in chapters) / len(chapters)\n",
        "\n",
        "    print(f\"ğŸ“Š {len(chapters)} chapters, {total_duration}s total, {avg_confidence:.1%} avg confidence\\n\")\n",
        "\n",
        "    for ch in chapters:\n",
        "        start_min, start_sec = ch['start_time'] // 60, ch['start_time'] % 60\n",
        "        end_min, end_sec = ch['end_time'] // 60, ch['end_time'] % 60\n",
        "\n",
        "        print(f\"Chapter {ch['chapter_number']} | {start_min:02d}:{start_sec:02d} - {end_min:02d}:{end_sec:02d} | \"\n",
        "              f\"Confidence: {ch['confidence_score']:.0%}\")\n",
        "        print(f\"ğŸ·ï¸  {ch['title']}\")\n",
        "        print(f\"ğŸ“  {ch['summary']}\")\n",
        "        print(f\"ğŸ­  {ch['emotion']['primary_emotion']} ({ch['emotion']['primary_score']:.0%}) | \"\n",
        "              f\"â±ï¸  {ch['duration_seconds']}s | ğŸ“Š {ch['word_count']} words\\n\")\n",
        "# =============================\n",
        "# YOUTUBE CHAPTER EVALUATION SYSTEM\n",
        "# =============================\n",
        "\n",
        "import yt_dlp\n",
        "import json\n",
        "import numpy as np\n",
        "from difflib import SequenceMatcher\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import re\n",
        "\n",
        "# =============================\n",
        "# 1. EXTRACT OFFICIAL YOUTUBE CHAPTERS\n",
        "# =============================\n",
        "def extract_youtube_chapters(youtube_url):\n",
        "    \"\"\"\n",
        "    Extract official chapters from YouTube video metadata\n",
        "\n",
        "    Returns:\n",
        "        List of dicts with 'start_time', 'end_time', 'title'\n",
        "        Returns empty list if no chapters available\n",
        "    \"\"\"\n",
        "    print(\"ğŸ“¥ Extracting official YouTube chapters...\")\n",
        "\n",
        "    ydl_opts = {\n",
        "        'quiet': True,\n",
        "        'no_warnings': True,\n",
        "        'extract_flat': False,\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "            info = ydl.extract_info(youtube_url, download=False)\n",
        "\n",
        "            # Get video duration\n",
        "            duration = info.get('duration', 0)\n",
        "\n",
        "            # Extract chapters\n",
        "            chapters_raw = info.get('chapters', [])\n",
        "\n",
        "            if not chapters_raw:\n",
        "                print(\"âš ï¸ No official chapters found in video metadata\")\n",
        "                return []\n",
        "\n",
        "            # Format chapters\n",
        "            official_chapters = []\n",
        "            for i, chapter in enumerate(chapters_raw):\n",
        "                start_time = int(chapter.get('start_time', 0))\n",
        "                end_time = int(chapter.get('end_time', duration))\n",
        "                title = chapter.get('title', f'Chapter {i+1}')\n",
        "\n",
        "                official_chapters.append({\n",
        "                    'chapter_number': i + 1,\n",
        "                    'start_time': start_time,\n",
        "                    'end_time': end_time,\n",
        "                    'title': title,\n",
        "                    'duration_seconds': end_time - start_time\n",
        "                })\n",
        "\n",
        "            print(f\"âœ… Found {len(official_chapters)} official chapters\")\n",
        "            return official_chapters\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error extracting chapters: {e}\")\n",
        "        return []\n",
        "\n",
        "# =============================\n",
        "# 2. TIMESTAMP OVERLAP CALCULATION\n",
        "# =============================\n",
        "def calculate_overlap(start1, end1, start2, end2):\n",
        "    \"\"\"\n",
        "    Calculate overlap between two time ranges\n",
        "\n",
        "    Returns:\n",
        "        overlap_seconds: Number of seconds overlapping\n",
        "        overlap_percentage: Percentage of overlap relative to shorter range\n",
        "    \"\"\"\n",
        "    overlap_start = max(start1, start2)\n",
        "    overlap_end = min(end1, end2)\n",
        "    overlap_seconds = max(0, overlap_end - overlap_start)\n",
        "\n",
        "    duration1 = end1 - start1\n",
        "    duration2 = end2 - start2\n",
        "    shorter_duration = min(duration1, duration2)\n",
        "\n",
        "    overlap_percentage = (overlap_seconds / shorter_duration * 100) if shorter_duration > 0 else 0\n",
        "\n",
        "    return overlap_seconds, overlap_percentage\n",
        "\n",
        "def find_best_timestamp_match(generated_chapter, official_chapters):\n",
        "    \"\"\"\n",
        "    Find the official chapter with best timestamp overlap\n",
        "\n",
        "    Returns:\n",
        "        best_match: Official chapter dict\n",
        "        overlap_seconds: Overlap in seconds\n",
        "        overlap_percentage: Overlap percentage\n",
        "    \"\"\"\n",
        "    best_match = None\n",
        "    best_overlap_seconds = 0\n",
        "    best_overlap_percentage = 0\n",
        "\n",
        "    gen_start = generated_chapter['start_time']\n",
        "    gen_end = generated_chapter['end_time']\n",
        "\n",
        "    for official_chapter in official_chapters:\n",
        "        off_start = official_chapter['start_time']\n",
        "        off_end = official_chapter['end_time']\n",
        "\n",
        "        overlap_seconds, overlap_percentage = calculate_overlap(\n",
        "            gen_start, gen_end, off_start, off_end\n",
        "        )\n",
        "\n",
        "        if overlap_seconds > best_overlap_seconds:\n",
        "            best_overlap_seconds = overlap_seconds\n",
        "            best_overlap_percentage = overlap_percentage\n",
        "            best_match = official_chapter\n",
        "\n",
        "    return best_match, best_overlap_seconds, best_overlap_percentage\n",
        "\n",
        "# =============================\n",
        "# 3. TITLE SIMILARITY METRICS\n",
        "# =============================\n",
        "def fuzzy_similarity(str1, str2):\n",
        "    \"\"\"Calculate fuzzy string similarity (0-1)\"\"\"\n",
        "    return SequenceMatcher(None, str1.lower(), str2.lower()).ratio()\n",
        "\n",
        "def tfidf_cosine_similarity(str1, str2):\n",
        "    \"\"\"Calculate TF-IDF cosine similarity (0-1)\"\"\"\n",
        "    try:\n",
        "        vectorizer = TfidfVectorizer()\n",
        "        tfidf_matrix = vectorizer.fit_transform([str1, str2])\n",
        "        similarity = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])[0][0]\n",
        "        return similarity\n",
        "    except Exception:\n",
        "        return 0.0\n",
        "\n",
        "def jaccard_similarity(str1, str2):\n",
        "    \"\"\"Calculate Jaccard similarity of word sets (0-1)\"\"\"\n",
        "    words1 = set(str1.lower().split())\n",
        "    words2 = set(str2.lower().split())\n",
        "\n",
        "    intersection = words1.intersection(words2)\n",
        "    union = words1.union(words2)\n",
        "\n",
        "    return len(intersection) / len(union) if union else 0.0\n",
        "\n",
        "def calculate_title_similarity(title1, title2):\n",
        "    \"\"\"\n",
        "    Calculate comprehensive title similarity using multiple metrics\n",
        "\n",
        "    Returns:\n",
        "        Dict with fuzzy, tfidf, jaccard scores and average\n",
        "    \"\"\"\n",
        "    fuzzy_score = fuzzy_similarity(title1, title2)\n",
        "    tfidf_score = tfidf_cosine_similarity(title1, title2)\n",
        "    jaccard_score = jaccard_similarity(title1, title2)\n",
        "\n",
        "    average_score = (fuzzy_score + tfidf_score + jaccard_score) / 3\n",
        "\n",
        "    return {\n",
        "        'fuzzy': round(fuzzy_score, 3),\n",
        "        'tfidf': round(tfidf_score, 3),\n",
        "        'jaccard': round(jaccard_score, 3),\n",
        "        'average': round(average_score, 3)\n",
        "    }\n",
        "\n",
        "# =============================\n",
        "# 4. CHAPTER ALIGNMENT\n",
        "# =============================\n",
        "def align_chapters(generated_chapters, official_chapters):\n",
        "    \"\"\"\n",
        "    Align generated chapters with official chapters\n",
        "\n",
        "    Returns:\n",
        "        List of alignment results with timestamps and title similarities\n",
        "    \"\"\"\n",
        "    print(\"\\nğŸ” Aligning generated chapters with official chapters...\")\n",
        "\n",
        "    alignments = []\n",
        "\n",
        "    for gen_chapter in generated_chapters:\n",
        "        # Find best timestamp match\n",
        "        best_match, overlap_seconds, overlap_percentage = find_best_timestamp_match(\n",
        "            gen_chapter, official_chapters\n",
        "        )\n",
        "\n",
        "        if best_match:\n",
        "            # Calculate title similarity\n",
        "            title_similarity = calculate_title_similarity(\n",
        "                gen_chapter['title'],\n",
        "                best_match['title']\n",
        "            )\n",
        "\n",
        "            alignment = {\n",
        "                'generated_chapter_number': gen_chapter['chapter_number'],\n",
        "                'generated_title': gen_chapter['title'],\n",
        "                'generated_start': gen_chapter['start_time'],\n",
        "                'generated_end': gen_chapter['end_time'],\n",
        "                'generated_duration': gen_chapter['duration_seconds'],\n",
        "                'official_chapter_number': best_match['chapter_number'],\n",
        "                'official_title': best_match['title'],\n",
        "                'official_start': best_match['start_time'],\n",
        "                'official_end': best_match['end_time'],\n",
        "                'official_duration': best_match['duration_seconds'],\n",
        "                'overlap_seconds': overlap_seconds,\n",
        "                'overlap_percentage': round(overlap_percentage, 1),\n",
        "                'title_similarity': title_similarity,\n",
        "                'timestamp_offset_start': gen_chapter['start_time'] - best_match['start_time'],\n",
        "                'timestamp_offset_end': gen_chapter['end_time'] - best_match['end_time']\n",
        "            }\n",
        "\n",
        "            alignments.append(alignment)\n",
        "\n",
        "    return alignments\n",
        "\n",
        "# =============================\n",
        "# 5. EVALUATION METRICS\n",
        "# =============================\n",
        "def calculate_evaluation_metrics(alignments, generated_chapters, official_chapters):\n",
        "    \"\"\"\n",
        "    Calculate comprehensive evaluation metrics\n",
        "\n",
        "    Returns:\n",
        "        Dict with all evaluation metrics\n",
        "    \"\"\"\n",
        "    if not alignments:\n",
        "        return {\n",
        "            'error': 'No alignments found',\n",
        "            'num_official_chapters': len(official_chapters),\n",
        "            'num_generated_chapters': len(generated_chapters)\n",
        "        }\n",
        "\n",
        "    # Basic counts\n",
        "    num_official = len(official_chapters)\n",
        "    num_generated = len(generated_chapters)\n",
        "    num_aligned = len(alignments)\n",
        "\n",
        "    # Timestamp metrics\n",
        "    overlap_percentages = [a['overlap_percentage'] for a in alignments]\n",
        "    avg_overlap = np.mean(overlap_percentages)\n",
        "    median_overlap = np.median(overlap_percentages)\n",
        "    min_overlap = np.min(overlap_percentages)\n",
        "    max_overlap = np.max(overlap_percentages)\n",
        "\n",
        "    # Count chapters with good overlap (>50%)\n",
        "    good_overlap_count = sum(1 for o in overlap_percentages if o >= 50)\n",
        "\n",
        "    # Title similarity metrics\n",
        "    avg_title_similarities = [a['title_similarity']['average'] for a in alignments]\n",
        "    fuzzy_scores = [a['title_similarity']['fuzzy'] for a in alignments]\n",
        "    tfidf_scores = [a['title_similarity']['tfidf'] for a in alignments]\n",
        "    jaccard_scores = [a['title_similarity']['jaccard'] for a in alignments]\n",
        "\n",
        "    avg_title_sim = np.mean(avg_title_similarities)\n",
        "    median_title_sim = np.median(avg_title_similarities)\n",
        "\n",
        "    # Count chapters with good title similarity (>0.5)\n",
        "    good_title_count = sum(1 for s in avg_title_similarities if s >= 0.5)\n",
        "\n",
        "    # Timestamp offset analysis\n",
        "    start_offsets = [abs(a['timestamp_offset_start']) for a in alignments]\n",
        "    end_offsets = [abs(a['timestamp_offset_end']) for a in alignments]\n",
        "\n",
        "    avg_start_offset = np.mean(start_offsets)\n",
        "    avg_end_offset = np.mean(end_offsets)\n",
        "\n",
        "    # Overall quality score (0-100)\n",
        "    # Weighted: 50% timestamp overlap + 30% title similarity + 20% chapter count match\n",
        "    timestamp_score = avg_overlap\n",
        "    title_score = avg_title_sim * 100\n",
        "    count_match_score = (min(num_generated, num_official) / max(num_generated, num_official)) * 100\n",
        "\n",
        "    overall_score = (timestamp_score * 0.5 + title_score * 0.3 + count_match_score * 0.2)\n",
        "\n",
        "    return {\n",
        "        # Chapter counts\n",
        "        'num_official_chapters': num_official,\n",
        "        'num_generated_chapters': num_generated,\n",
        "        'num_aligned_chapters': num_aligned,\n",
        "        'chapter_count_match_ratio': round(min(num_generated, num_official) / max(num_generated, num_official), 3),\n",
        "\n",
        "        # Timestamp overlap metrics\n",
        "        'avg_overlap_percentage': round(avg_overlap, 1),\n",
        "        'median_overlap_percentage': round(median_overlap, 1),\n",
        "        'min_overlap_percentage': round(min_overlap, 1),\n",
        "        'max_overlap_percentage': round(max_overlap, 1),\n",
        "        'chapters_with_good_overlap_50plus': good_overlap_count,\n",
        "        'good_overlap_ratio': round(good_overlap_count / num_aligned, 3) if num_aligned > 0 else 0,\n",
        "\n",
        "        # Title similarity metrics\n",
        "        'avg_title_similarity': round(avg_title_sim, 3),\n",
        "        'median_title_similarity': round(median_title_sim, 3),\n",
        "        'avg_fuzzy_similarity': round(np.mean(fuzzy_scores), 3),\n",
        "        'avg_tfidf_similarity': round(np.mean(tfidf_scores), 3),\n",
        "        'avg_jaccard_similarity': round(np.mean(jaccard_scores), 3),\n",
        "        'chapters_with_good_title_sim_50plus': good_title_count,\n",
        "        'good_title_sim_ratio': round(good_title_count / num_aligned, 3) if num_aligned > 0 else 0,\n",
        "\n",
        "        # Timestamp offset analysis\n",
        "        'avg_start_time_offset_seconds': round(avg_start_offset, 1),\n",
        "        'avg_end_time_offset_seconds': round(avg_end_offset, 1),\n",
        "\n",
        "        # Overall quality score\n",
        "        'overall_quality_score': round(overall_score, 1)\n",
        "    }\n",
        "\n",
        "# =============================\n",
        "# 6. EVALUATION REPORT\n",
        "# =============================\n",
        "def generate_evaluation_report(alignments, metrics, official_chapters, generated_chapters):\n",
        "    \"\"\"\n",
        "    Generate comprehensive evaluation report\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"ğŸ“Š CHAPTER GENERATION EVALUATION REPORT\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Summary statistics\n",
        "    print(\"\\nğŸ“ˆ SUMMARY STATISTICS\")\n",
        "    print(\"-\" * 80)\n",
        "    print(f\"Official Chapters:     {metrics['num_official_chapters']}\")\n",
        "    print(f\"Generated Chapters:    {metrics['num_generated_chapters']}\")\n",
        "    print(f\"Aligned Chapters:      {metrics['num_aligned_chapters']}\")\n",
        "    print(f\"Chapter Count Match:   {metrics['chapter_count_match_ratio']:.1%}\")\n",
        "\n",
        "    # Overall quality score\n",
        "    print(f\"\\nğŸ¯ OVERALL QUALITY SCORE: {metrics['overall_quality_score']:.1f}/100\")\n",
        "\n",
        "    # Timestamp evaluation\n",
        "    print(\"\\nâ±ï¸ TIMESTAMP OVERLAP ANALYSIS\")\n",
        "    print(\"-\" * 80)\n",
        "    print(f\"Average Overlap:       {metrics['avg_overlap_percentage']:.1f}%\")\n",
        "    print(f\"Median Overlap:        {metrics['median_overlap_percentage']:.1f}%\")\n",
        "    print(f\"Range:                 {metrics['min_overlap_percentage']:.1f}% - {metrics['max_overlap_percentage']:.1f}%\")\n",
        "    print(f\"Good Overlaps (>50%):  {metrics['chapters_with_good_overlap_50plus']}/{metrics['num_aligned_chapters']} ({metrics['good_overlap_ratio']:.1%})\")\n",
        "    print(f\"Avg Start Offset:      {metrics['avg_start_time_offset_seconds']:.1f}s\")\n",
        "    print(f\"Avg End Offset:        {metrics['avg_end_time_offset_seconds']:.1f}s\")\n",
        "\n",
        "    # Title similarity evaluation\n",
        "    print(\"\\nğŸ“ TITLE SIMILARITY ANALYSIS\")\n",
        "    print(\"-\" * 80)\n",
        "    print(f\"Average Similarity:    {metrics['avg_title_similarity']:.3f} (0-1 scale)\")\n",
        "    print(f\"Median Similarity:     {metrics['median_title_similarity']:.3f}\")\n",
        "    print(f\"  - Fuzzy Matching:    {metrics['avg_fuzzy_similarity']:.3f}\")\n",
        "    print(f\"  - TF-IDF Cosine:     {metrics['avg_tfidf_similarity']:.3f}\")\n",
        "    print(f\"  - Jaccard (words):   {metrics['avg_jaccard_similarity']:.3f}\")\n",
        "    print(f\"Good Matches (>0.5):   {metrics['chapters_with_good_title_sim_50plus']}/{metrics['num_aligned_chapters']} ({metrics['good_title_sim_ratio']:.1%})\")\n",
        "\n",
        "    # Detailed chapter-by-chapter comparison\n",
        "    print(\"\\nğŸ“‹ DETAILED CHAPTER COMPARISON\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    for alignment in alignments:\n",
        "        print(f\"\\nGenerated Chapter {alignment['generated_chapter_number']} vs Official Chapter {alignment['official_chapter_number']}\")\n",
        "        print(f\"  Generated: [{alignment['generated_start']}s - {alignment['generated_end']}s] \\\"{alignment['generated_title']}\\\"\")\n",
        "        print(f\"  Official:  [{alignment['official_start']}s - {alignment['official_end']}s] \\\"{alignment['official_title']}\\\"\")\n",
        "        print(f\"  Overlap:   {alignment['overlap_percentage']:.1f}% ({alignment['overlap_seconds']}s)\")\n",
        "        print(f\"  Title Sim: {alignment['title_similarity']['average']:.3f} (fuzzy={alignment['title_similarity']['fuzzy']:.2f}, tfidf={alignment['title_similarity']['tfidf']:.2f}, jaccard={alignment['title_similarity']['jaccard']:.2f})\")\n",
        "        print(f\"  Offsets:   Start {alignment['timestamp_offset_start']:+d}s, End {alignment['timestamp_offset_end']:+d}s\")\n",
        "\n",
        "    # Gaps and mismatches\n",
        "    print(\"\\nâš ï¸ GAPS AND MISMATCHES\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    # Find unmatched official chapters\n",
        "    matched_official = set(a['official_chapter_number'] for a in alignments)\n",
        "    unmatched_official = [ch for ch in official_chapters if ch['chapter_number'] not in matched_official]\n",
        "\n",
        "    if unmatched_official:\n",
        "        print(f\"\\nâŒ {len(unmatched_official)} official chapter(s) not matched:\")\n",
        "        for ch in unmatched_official:\n",
        "            print(f\"  - Chapter {ch['chapter_number']}: [{ch['start_time']}s - {ch['end_time']}s] \\\"{ch['title']}\\\"\")\n",
        "    else:\n",
        "        print(\"\\nâœ… All official chapters have matches\")\n",
        "\n",
        "    # Find chapters with poor overlap\n",
        "    poor_overlap = [a for a in alignments if a['overlap_percentage'] < 30]\n",
        "    if poor_overlap:\n",
        "        print(f\"\\nâš ï¸ {len(poor_overlap)} chapter(s) with poor overlap (<30%):\")\n",
        "        for a in poor_overlap:\n",
        "            print(f\"  - Generated {a['generated_chapter_number']} ({a['overlap_percentage']:.1f}% overlap)\")\n",
        "\n",
        "    # Find chapters with poor title match\n",
        "    poor_titles = [a for a in alignments if a['title_similarity']['average'] < 0.3]\n",
        "    if poor_titles:\n",
        "        print(f\"\\nâš ï¸ {len(poor_titles)} chapter(s) with poor title similarity (<0.3):\")\n",
        "        for a in poor_titles:\n",
        "            print(f\"  - Generated: \\\"{a['generated_title']}\\\"\")\n",
        "            print(f\"    Official:  \\\"{a['official_title']}\\\" (sim={a['title_similarity']['average']:.2f})\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "\n",
        "# =============================\n",
        "# 7. MAIN EVALUATION FUNCTION\n",
        "# =============================\n",
        "def evaluate_chapters(youtube_url, generated_chapters, save_report=True):\n",
        "    \"\"\"\n",
        "    Complete evaluation pipeline\n",
        "\n",
        "    Args:\n",
        "        youtube_url: YouTube video URL\n",
        "        generated_chapters: List of dicts from your pipeline\n",
        "        save_report: Whether to save JSON report\n",
        "\n",
        "    Returns:\n",
        "        Dict with alignments and metrics\n",
        "    \"\"\"\n",
        "    # Extract official chapters\n",
        "    official_chapters = extract_youtube_chapters(youtube_url)\n",
        "\n",
        "    if not official_chapters:\n",
        "        print(\"\\nâš ï¸ Cannot evaluate: No official chapters available\")\n",
        "        return {\n",
        "            'error': 'No official chapters',\n",
        "            'official_chapters': [],\n",
        "            'generated_chapters': generated_chapters\n",
        "        }\n",
        "\n",
        "    # Align chapters\n",
        "    alignments = align_chapters(generated_chapters, official_chapters)\n",
        "\n",
        "    # Calculate metrics\n",
        "    metrics = calculate_evaluation_metrics(alignments, generated_chapters, official_chapters)\n",
        "\n",
        "    # Generate report\n",
        "    generate_evaluation_report(alignments, metrics, official_chapters, generated_chapters)\n",
        "\n",
        "    # Save results\n",
        "    results = {\n",
        "        'official_chapters': official_chapters,\n",
        "        'generated_chapters': generated_chapters,\n",
        "        'alignments': alignments,\n",
        "        'metrics': metrics\n",
        "    }\n",
        "\n",
        "    if save_report:\n",
        "        with open('/kaggle/working/evaluation_report.json', 'w') as f:\n",
        "            json.dump(results, f, indent=2)\n",
        "        print(\"\\nğŸ’¾ Evaluation report saved to: evaluation_report.json\")\n",
        "\n",
        "    return results\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdMrrEsi04CF",
        "outputId": "40d3cd0f-1471-420e-fc27-ebb0fd6fbea8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting streamlit_app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile streamlit_app.py\n",
        "# =============================\n",
        "# STREAMLIT VIDEO CHAPTER GENERATOR\n",
        "# For Kaggle Notebooks\n",
        "# =============================\n",
        "\n",
        "import streamlit as st\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from datetime import timedelta\n",
        "import base64\n",
        "import cv2\n",
        "import traceback\n",
        "from chapter_pipeline import (\n",
        "    load_models, clear_cache, download_youtube_video,\n",
        "    extract_key_frames, detect_meaningful_scenes,\n",
        "    create_quality_summary, analyze_emotion,\n",
        "    generate_chapter_title, calculate_confidence_score,\n",
        "    evaluate_chapters\n",
        ")\n",
        "\n",
        "\n",
        "# Import your pipeline functions\n",
        "# Note: In Kaggle, make sure both scripts are in the same directory\n",
        "# or adjust imports accordingly\n",
        "# Progress helper: accepts either 0-100 or 0.0-1.0 and normalizes to 0.0-1.0\n",
        "def set_progress(pb, value):\n",
        "    \"\"\"\n",
        "    pb: streamlit progress object (st.progress(...))\n",
        "    value: either a float between 0.0 and 1.0, or a number 0-100\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Convert possible numpy types to native python float/int\n",
        "        v = float(value)\n",
        "    except Exception:\n",
        "        return\n",
        "\n",
        "    # If given percentage style (greater than 1), assume 0-100 scale\n",
        "    if v > 1.0:\n",
        "        v = max(0.0, min(100.0, v)) / 100.0\n",
        "    else:\n",
        "        v = max(0.0, min(1.0, v))\n",
        "\n",
        "    pb.progress(v)\n",
        "\n",
        "# =============================\n",
        "# PAGE CONFIG\n",
        "# =============================\n",
        "st.set_page_config(\n",
        "    page_title=\"AI Video Chapter Generator\",\n",
        "    page_icon=\"ğŸ¬\",\n",
        "    layout=\"wide\",\n",
        "    initial_sidebar_state=\"expanded\"\n",
        ")\n",
        "\n",
        "# =============================\n",
        "# CUSTOM CSS\n",
        "# =============================\n",
        "st.markdown(\"\"\"\n",
        "<style>\n",
        "    .main-header {\n",
        "        font-size: 3rem;\n",
        "        font-weight: bold;\n",
        "        text-align: center;\n",
        "        color: #FF4B4B;\n",
        "        margin-bottom: 1rem;\n",
        "    }\n",
        "    .sub-header {\n",
        "        font-size: 1.2rem;\n",
        "        text-align: center;\n",
        "        color: #666;\n",
        "        margin-bottom: 2rem;\n",
        "    }\n",
        "    .metric-card {\n",
        "        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "        padding: 1.5rem;\n",
        "        border-radius: 10px;\n",
        "        color: white;\n",
        "        box-shadow: 0 4px 6px rgba(0,0,0,0.1);\n",
        "    }\n",
        "    .chapter-card {\n",
        "        background: #f8f9fa;\n",
        "        padding: 1.5rem;\n",
        "        border-radius: 10px;\n",
        "        border-left: 4px solid #667eea;\n",
        "        margin-bottom: 1rem;\n",
        "    }\n",
        "    .success-box {\n",
        "        background: #d4edda;\n",
        "        border: 1px solid #c3e6cb;\n",
        "        padding: 1rem;\n",
        "        border-radius: 5px;\n",
        "        color: #155724;\n",
        "    }\n",
        "    .warning-box {\n",
        "        background: #fff3cd;\n",
        "        border: 1px solid #ffeaa7;\n",
        "        padding: 1rem;\n",
        "        border-radius: 5px;\n",
        "        color: #856404;\n",
        "    }\n",
        "    .stProgress > div > div > div > div {\n",
        "        background: linear-gradient(to right, #667eea, #764ba2);\n",
        "    }\n",
        "</style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "# =============================\n",
        "# HELPER FUNCTIONS\n",
        "# =============================\n",
        "def format_timestamp(seconds):\n",
        "    \"\"\"Convert seconds to MM:SS format\"\"\"\n",
        "    return str(timedelta(seconds=int(seconds)))[2:]\n",
        "\n",
        "def get_emotion_emoji(emotion):\n",
        "    \"\"\"Get emoji for emotion\"\"\"\n",
        "    emoji_map = {\n",
        "        'joy': 'ğŸ˜Š',\n",
        "        'surprise': 'ğŸ˜®',\n",
        "        'neutral': 'ğŸ˜',\n",
        "        'anger': 'ğŸ˜ ',\n",
        "        'sadness': 'ğŸ˜¢',\n",
        "        'fear': 'ğŸ˜¨',\n",
        "        'disgust': 'ğŸ¤¢'\n",
        "    }\n",
        "    return emoji_map.get(emotion.lower(), 'ğŸ˜')\n",
        "\n",
        "def create_timeline_chart(chapters):\n",
        "    \"\"\"Create interactive timeline visualization\"\"\"\n",
        "    fig = go.Figure()\n",
        "\n",
        "    colors = px.colors.qualitative.Plotly\n",
        "\n",
        "    for i, ch in enumerate(chapters):\n",
        "        fig.add_trace(go.Bar(\n",
        "            x=[ch['duration_seconds']],\n",
        "            y=[ch['title']],\n",
        "            orientation='h',\n",
        "            name=f\"Chapter {ch['chapter_number']}\",\n",
        "            text=f\"{ch['duration_seconds']}s\",\n",
        "            textposition='inside',\n",
        "            marker=dict(color=colors[i % len(colors)]),\n",
        "            hovertemplate=(\n",
        "                f\"<b>{ch['title']}</b><br>\"\n",
        "                f\"Duration: {ch['duration_seconds']}s<br>\"\n",
        "                f\"Time: {format_timestamp(ch['start_time'])} - {format_timestamp(ch['end_time'])}<br>\"\n",
        "                f\"Confidence: {ch['confidence_score']:.0%}<br>\"\n",
        "                f\"<extra></extra>\"\n",
        "            )\n",
        "        ))\n",
        "\n",
        "    fig.update_layout(\n",
        "        title=\"Chapter Timeline\",\n",
        "        xaxis_title=\"Duration (seconds)\",\n",
        "        yaxis_title=\"Chapters\",\n",
        "        height=max(400, len(chapters) * 60),\n",
        "        showlegend=False,\n",
        "        plot_bgcolor='rgba(0,0,0,0)',\n",
        "        paper_bgcolor='rgba(0,0,0,0)',\n",
        "    )\n",
        "\n",
        "    return fig\n",
        "\n",
        "def create_emotion_distribution(chapters):\n",
        "    \"\"\"Create emotion distribution pie chart\"\"\"\n",
        "    emotions = [ch['emotion']['primary_emotion'] for ch in chapters]\n",
        "    emotion_counts = pd.Series(emotions).value_counts()\n",
        "\n",
        "    fig = go.Figure(data=[go.Pie(\n",
        "        labels=emotion_counts.index,\n",
        "        values=emotion_counts.values,\n",
        "        hole=.3,\n",
        "        marker=dict(colors=px.colors.qualitative.Set2)\n",
        "    )])\n",
        "\n",
        "    fig.update_layout(\n",
        "        title=\"Emotional Distribution Across Chapters\",\n",
        "        height=400\n",
        "    )\n",
        "\n",
        "    return fig\n",
        "\n",
        "def create_confidence_chart(chapters):\n",
        "    \"\"\"Create confidence score chart\"\"\"\n",
        "    chapter_nums = [ch['chapter_number'] for ch in chapters]\n",
        "    confidences = [ch['confidence_score'] * 100 for ch in chapters]\n",
        "\n",
        "    fig = go.Figure()\n",
        "\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=chapter_nums,\n",
        "        y=confidences,\n",
        "        mode='lines+markers',\n",
        "        name='Confidence',\n",
        "        line=dict(color='#667eea', width=3),\n",
        "        marker=dict(size=10, color='#764ba2'),\n",
        "        fill='tozeroy',\n",
        "        fillcolor='rgba(102, 126, 234, 0.2)'\n",
        "    ))\n",
        "\n",
        "    fig.add_hline(y=70, line_dash=\"dash\", line_color=\"green\",\n",
        "                  annotation_text=\"Good Quality (70%)\")\n",
        "\n",
        "    fig.update_layout(\n",
        "        title=\"Chapter Quality Confidence Scores\",\n",
        "        xaxis_title=\"Chapter Number\",\n",
        "        yaxis_title=\"Confidence Score (%)\",\n",
        "        height=400,\n",
        "        yaxis=dict(range=[0, 100])\n",
        "    )\n",
        "\n",
        "    return fig\n",
        "\n",
        "def create_evaluation_charts(metrics, alignments):\n",
        "    \"\"\"Create evaluation visualization charts\"\"\"\n",
        "    charts = {}\n",
        "\n",
        "    # Overlap distribution\n",
        "    if alignments:\n",
        "        overlap_data = [a['overlap_percentage'] for a in alignments]\n",
        "        fig = go.Figure(data=[go.Histogram(\n",
        "            x=overlap_data,\n",
        "            nbinsx=10,\n",
        "            marker_color='#667eea'\n",
        "        )])\n",
        "        fig.update_layout(\n",
        "            title=\"Timestamp Overlap Distribution\",\n",
        "            xaxis_title=\"Overlap Percentage\",\n",
        "            yaxis_title=\"Count\",\n",
        "            height=300\n",
        "        )\n",
        "        charts['overlap_hist'] = fig\n",
        "\n",
        "        # Title similarity comparison\n",
        "        chapters = [f\"Ch {a['generated_chapter_number']}\" for a in alignments]\n",
        "        fuzzy = [a['title_similarity']['fuzzy'] for a in alignments]\n",
        "        tfidf = [a['title_similarity']['tfidf'] for a in alignments]\n",
        "        jaccard = [a['title_similarity']['jaccard'] for a in alignments]\n",
        "\n",
        "        fig = go.Figure()\n",
        "        fig.add_trace(go.Bar(name='Fuzzy', x=chapters, y=fuzzy, marker_color='#667eea'))\n",
        "        fig.add_trace(go.Bar(name='TF-IDF', x=chapters, y=tfidf, marker_color='#764ba2'))\n",
        "        fig.add_trace(go.Bar(name='Jaccard', x=chapters, y=jaccard, marker_color='#f093fb'))\n",
        "\n",
        "        fig.update_layout(\n",
        "            title=\"Title Similarity Scores by Method\",\n",
        "            xaxis_title=\"Chapter\",\n",
        "            yaxis_title=\"Similarity Score\",\n",
        "            barmode='group',\n",
        "            height=400\n",
        "        )\n",
        "        charts['similarity_bar'] = fig\n",
        "\n",
        "    return charts\n",
        "\n",
        "def download_json(data, filename):\n",
        "    \"\"\"Create download link for JSON data\"\"\"\n",
        "    json_str = json.dumps(data, indent=2, ensure_ascii=False)\n",
        "    b64 = base64.b64encode(json_str.encode()).decode()\n",
        "    href = f'<a href=\"data:application/json;base64,{b64}\" download=\"{filename}\">ğŸ“¥ Download {filename}</a>'\n",
        "    return href\n",
        "\n",
        "# =============================\n",
        "# SESSION STATE INITIALIZATION\n",
        "# =============================\n",
        "if 'chapters' not in st.session_state:\n",
        "    st.session_state.chapters = None\n",
        "if 'evaluation_results' not in st.session_state:\n",
        "    st.session_state.evaluation_results = None\n",
        "if 'processing' not in st.session_state:\n",
        "    st.session_state.processing = False\n",
        "if 'models_loaded' not in st.session_state:\n",
        "    st.session_state.models_loaded = False\n",
        "if 'models' not in st.session_state:\n",
        "    st.session_state.models = None\n",
        "\n",
        "# =============================\n",
        "# HEADER\n",
        "# =============================\n",
        "st.markdown('<div class=\"main-header\">ğŸ¬ AI Video Chapter Generator</div>', unsafe_allow_html=True)\n",
        "st.markdown('<div class=\"sub-header\">Transform YouTube videos into intelligent chapters with semantic analysis</div>', unsafe_allow_html=True)\n",
        "\n",
        "# =============================\n",
        "# SIDEBAR - SETTINGS\n",
        "# =============================\n",
        "with st.sidebar:\n",
        "    st.image(\"https://img.icons8.com/fluency/96/000000/video.png\", width=80)\n",
        "    st.title(\"âš™ï¸ Settings\")\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "\n",
        "    # Model loading\n",
        "    st.subheader(\"ğŸ¤– AI Models\")\n",
        "    if not st.session_state.models_loaded:\n",
        "        if st.button(\"ğŸ”„ Load AI Models\", use_container_width=True):\n",
        "            with st.spinner(\"Loading models...\"):\n",
        "                try:\n",
        "\n",
        "                    st.session_state.models = load_models()\n",
        "                    st.session_state.models_loaded = True\n",
        "                    st.success(\"âœ… Models loaded!\")\n",
        "                except Exception as e:\n",
        "                    st.error(f\"âŒ Error loading models: {e}\")\n",
        "    else:\n",
        "        st.success(\"âœ… Models Ready\")\n",
        "        if st.button(\"ğŸ—‘ï¸ Clear Models\", use_container_width=True):\n",
        "\n",
        "            clear_cache()\n",
        "            st.session_state.models_loaded = False\n",
        "            st.session_state.models = None\n",
        "            st.rerun()\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "\n",
        "    # Processing options\n",
        "    st.subheader(\"ğŸ¯ Processing Options\")\n",
        "    target_frames = st.slider(\"Target Frames\", 30, 100, 60,\n",
        "                              help=\"Number of keyframes to extract\")\n",
        "    min_chapter_duration = st.slider(\"Min Chapter Duration (s)\", 20, 120, 45,\n",
        "                                     help=\"Minimum chapter length\")\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "\n",
        "    # Evaluation options\n",
        "    st.subheader(\"ğŸ“Š Evaluation\")\n",
        "    enable_evaluation = st.checkbox(\"Enable Chapter Evaluation\", value=True,\n",
        "                                   help=\"Compare with official YouTube chapters\")\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "\n",
        "    # Cache management\n",
        "    st.subheader(\"ğŸ§¹ Cache\")\n",
        "    if st.button(\"Clear All Cache\", use_container_width=True):\n",
        "        try:\n",
        "\n",
        "            clear_cache()\n",
        "            st.session_state.chapters = None\n",
        "            st.session_state.evaluation_results = None\n",
        "            st.success(\"âœ… Cache cleared!\")\n",
        "        except Exception as e:\n",
        "            st.error(f\"âŒ Error: {e}\")\n",
        "\n",
        "# =============================\n",
        "# MAIN CONTENT\n",
        "# =============================\n",
        "tabs = st.tabs([\"ğŸ¬ Generate Chapters\", \"ğŸ“Š Chapter Analysis\", \"ğŸ” Evaluation\"])\n",
        "\n",
        "# =============================\n",
        "# TAB 1: GENERATE CHAPTERS\n",
        "# =============================\n",
        "with tabs[0]:\n",
        "    st.header(\"Video Processing\")\n",
        "\n",
        "    col1, col2 = st.columns([3, 1])\n",
        "\n",
        "    with col1:\n",
        "        youtube_url = st.text_input(\n",
        "            \"ğŸ”— YouTube Video URL\",\n",
        "            placeholder=\"https://www.youtube.com/watch?v=...\",\n",
        "            help=\"Enter the full YouTube video URL\"\n",
        "        )\n",
        "\n",
        "    with col2:\n",
        "        st.write(\"\")\n",
        "        st.write(\"\")\n",
        "        process_button = st.button(\"ğŸš€ Process Video\", type=\"primary\", use_container_width=True)\n",
        "\n",
        "    if process_button:\n",
        "        if not youtube_url:\n",
        "            st.error(\"âš ï¸ Please enter a YouTube URL\")\n",
        "        elif not st.session_state.models_loaded:\n",
        "            st.error(\"âš ï¸ Please load AI models first (see sidebar)\")\n",
        "        else:\n",
        "            st.session_state.processing = True\n",
        "\n",
        "            progress_bar = st.progress(0)\n",
        "            status_text = st.empty()\n",
        "\n",
        "            try:\n",
        "                # Import functions\n",
        "\n",
        "\n",
        "                # Step 1: Download\n",
        "                status_text.text(\"ğŸ“¥ Downloading video...\")\n",
        "                set_progress(progress_bar, 10)\n",
        "                video_path = download_youtube_video(youtube_url)\n",
        "\n",
        "                if not video_path:\n",
        "                    st.error(\"âŒ Download failed\")\n",
        "                    st.stop()\n",
        "\n",
        "                # Step 2: Extract frames\n",
        "                status_text.text(\"ğŸ¬ Extracting keyframes...\")\n",
        "                set_progress(progress_bar, 25)\n",
        "                frame_features, frame_indices, frame_timestamps = extract_key_frames(\n",
        "                    video_path,\n",
        "                    st.session_state.models['clip_processor'],\n",
        "                    st.session_state.models['clip_model'],\n",
        "                    st.session_state.models['device'],\n",
        "                    target_frames=target_frames\n",
        "                )\n",
        "\n",
        "                # Get video metadata\n",
        "                cap = cv2.VideoCapture(video_path)\n",
        "                fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "                total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "                video_duration = total_frames / fps if fps > 0 else 0\n",
        "                cap.release()\n",
        "\n",
        "                # Step 3: Detect scenes\n",
        "                status_text.text(\"ğŸ­ Detecting scenes...\")\n",
        "                set_progress(progress_bar, 40)\n",
        "\n",
        "                if len(frame_features) == 0:\n",
        "                    scene_times = [0, video_duration * 0.25, video_duration * 0.5,\n",
        "                                  video_duration * 0.75, video_duration]\n",
        "                else:\n",
        "                    scene_indices = detect_meaningful_scenes(\n",
        "                        frame_features, frame_timestamps,\n",
        "                        min_chapter_seconds=min_chapter_duration\n",
        "                    )\n",
        "                    scene_times = [frame_timestamps[i] for i in scene_indices]\n",
        "                    scene_times.append(video_duration)\n",
        "\n",
        "                # Step 4: Transcribe\n",
        "                status_text.text(\"ğŸ™ï¸ Transcribing audio...\")\n",
        "                set_progress(progress_bar, 55)\n",
        "                transcript_result = st.session_state.models['whisper_model'].transcribe(video_path)\n",
        "                full_transcript = transcript_result[\"text\"]\n",
        "\n",
        "                # Step 5: Generate chapters\n",
        "                status_text.text(\"ğŸ“š Generating chapters...\")\n",
        "                set_progress(progress_bar, 70)\n",
        "\n",
        "                chapters = []\n",
        "                words = full_transcript.split()\n",
        "                words_per_second = len(words) / video_duration if video_duration > 0 else 2\n",
        "\n",
        "                for i in range(len(scene_times) - 1):\n",
        "                    start_time = scene_times[i]\n",
        "                    end_time = scene_times[i + 1]\n",
        "                    duration = end_time - start_time\n",
        "\n",
        "                    if duration < 20:\n",
        "                        continue\n",
        "\n",
        "                    start_word_idx = max(0, min(int(start_time * words_per_second), len(words) - 1))\n",
        "                    end_word_idx = min(len(words), int(end_time * words_per_second))\n",
        "\n",
        "                    word_count = end_word_idx - start_word_idx\n",
        "                    if word_count < 10:\n",
        "                        continue\n",
        "\n",
        "                    chapter_text = \" \".join(words[start_word_idx:end_word_idx])\n",
        "\n",
        "                    # Generate metadata\n",
        "                    summary = create_quality_summary(chapter_text, st.session_state.models['summarizer'])\n",
        "                    emotion_data = analyze_emotion(chapter_text, st.session_state.models['emotion_classifier'])\n",
        "                    title = generate_chapter_title(\n",
        "                        summary_text=summary,\n",
        "                        chapter_index=len(chapters),\n",
        "                        emotion_data=emotion_data,\n",
        "                        title_generator=st.session_state.models['title_generator']\n",
        "                    )\n",
        "\n",
        "                    chapter = {\n",
        "                        \"chapter_number\": len(chapters) + 1,\n",
        "                        \"title\": title,\n",
        "                        \"start_time\": int(start_time),\n",
        "                        \"end_time\": int(end_time),\n",
        "                        \"duration_seconds\": int(duration),\n",
        "                        \"start_word\": start_word_idx,\n",
        "                        \"end_word\": end_word_idx,\n",
        "                        \"summary\": summary,\n",
        "                        \"emotion\": emotion_data,\n",
        "                        \"word_count\": word_count\n",
        "                    }\n",
        "\n",
        "                    chapter[\"confidence_score\"] = calculate_confidence_score(chapter)\n",
        "                    chapters.append(chapter)\n",
        "\n",
        "                    percent = 70 + (i / max(1, (len(scene_times) - 1))) * 20\n",
        "                    set_progress(progress_bar, min(100, percent))\n",
        "\n",
        "                    st.session_state.chapters = chapters\n",
        "\n",
        "                # Step 6: Evaluation (optional)\n",
        "                if enable_evaluation and chapters:\n",
        "                    status_text.text(\"ğŸ” Evaluating chapters...\")\n",
        "                    set_progress(progress_bar, 95)\n",
        "\n",
        "                    try:\n",
        "\n",
        "                        eval_results = evaluate_chapters(youtube_url, chapters, save_report=False)\n",
        "                        st.session_state.evaluation_results = eval_results\n",
        "                    except Exception as e:\n",
        "                        st.warning(f\"âš ï¸ Evaluation failed: {e}\")\n",
        "\n",
        "                set_progress(progress_bar, 100)\n",
        "                status_text.text(\"âœ… Processing complete!\")\n",
        "\n",
        "                st.success(f\"ğŸ‰ Successfully generated {len(chapters)} chapters!\")\n",
        "\n",
        "                # Save to file\n",
        "                with open('/kaggle/working/final_chapters.json', 'w', encoding='utf-8') as f:\n",
        "                    json.dump(chapters, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "            except Exception as e:\n",
        "                st.error(f\"âŒ Processing failed: {e}\")\n",
        "\n",
        "                st.code(traceback.format_exc())\n",
        "\n",
        "            finally:\n",
        "                st.session_state.processing = False\n",
        "\n",
        "    # Display results\n",
        "    if st.session_state.chapters:\n",
        "        st.markdown(\"---\")\n",
        "        st.subheader(\"ğŸ“‹ Generated Chapters\")\n",
        "\n",
        "        # Summary metrics\n",
        "        col1, col2, col3, col4 = st.columns(4)\n",
        "\n",
        "        with col1:\n",
        "            st.metric(\"Total Chapters\", len(st.session_state.chapters))\n",
        "\n",
        "        with col2:\n",
        "            total_duration = sum(ch['duration_seconds'] for ch in st.session_state.chapters)\n",
        "            st.metric(\"Total Duration\", f\"{total_duration}s\")\n",
        "\n",
        "        with col3:\n",
        "            avg_confidence = sum(ch['confidence_score'] for ch in st.session_state.chapters) / len(st.session_state.chapters)\n",
        "            st.metric(\"Avg Confidence\", f\"{avg_confidence:.0%}\")\n",
        "\n",
        "        with col4:\n",
        "            avg_duration = total_duration / len(st.session_state.chapters)\n",
        "            st.metric(\"Avg Chapter Length\", f\"{int(avg_duration)}s\")\n",
        "\n",
        "        st.markdown(\"---\")\n",
        "\n",
        "        # Chapter cards\n",
        "        for ch in st.session_state.chapters:\n",
        "            with st.expander(f\"**Chapter {ch['chapter_number']}: {ch['title']}** ({format_timestamp(ch['start_time'])} - {format_timestamp(ch['end_time'])})\"):\n",
        "                col1, col2 = st.columns([2, 1])\n",
        "\n",
        "                with col1:\n",
        "                    st.markdown(f\"**ğŸ“ Summary:**\")\n",
        "                    st.write(ch['summary'])\n",
        "\n",
        "                    st.markdown(f\"**ğŸ­ Emotion:** {get_emotion_emoji(ch['emotion']['primary_emotion'])} {ch['emotion']['primary_emotion'].title()} ({ch['emotion']['primary_score']:.0%})\")\n",
        "\n",
        "                with col2:\n",
        "                    st.markdown(f\"**â±ï¸ Duration:** {ch['duration_seconds']}s\")\n",
        "                    st.markdown(f\"**ğŸ“Š Words:** {ch['word_count']}\")\n",
        "                    st.markdown(f\"**âœ… Confidence:** {ch['confidence_score']:.0%}\")\n",
        "\n",
        "                    # Progress bar for confidence\n",
        "                    st.progress(ch['confidence_score'])\n",
        "\n",
        "        # Download button\n",
        "        st.markdown(\"---\")\n",
        "        st.markdown(download_json(st.session_state.chapters, \"chapters.json\"), unsafe_allow_html=True)\n",
        "\n",
        "# =============================\n",
        "# TAB 2: CHAPTER ANALYSIS\n",
        "# =============================\n",
        "with tabs[1]:\n",
        "    st.header(\"Chapter Analysis & Visualization\")\n",
        "\n",
        "    if st.session_state.chapters:\n",
        "        # Timeline\n",
        "        st.subheader(\"ğŸ“Š Chapter Timeline\")\n",
        "        timeline_chart = create_timeline_chart(st.session_state.chapters)\n",
        "        st.plotly_chart(timeline_chart, use_container_width=True)\n",
        "\n",
        "        col1, col2 = st.columns(2)\n",
        "\n",
        "        with col1:\n",
        "            # Emotion distribution\n",
        "            st.subheader(\"ğŸ­ Emotional Distribution\")\n",
        "            emotion_chart = create_emotion_distribution(st.session_state.chapters)\n",
        "            st.plotly_chart(emotion_chart, use_container_width=True)\n",
        "\n",
        "        with col2:\n",
        "            # Confidence scores\n",
        "            st.subheader(\"âœ… Quality Confidence\")\n",
        "            confidence_chart = create_confidence_chart(st.session_state.chapters)\n",
        "            st.plotly_chart(confidence_chart, use_container_width=True)\n",
        "\n",
        "        # Data table\n",
        "        st.subheader(\"ğŸ“‹ Chapter Data Table\")\n",
        "        df = pd.DataFrame([{\n",
        "            'Chapter': ch['chapter_number'],\n",
        "            'Title': ch['title'],\n",
        "            'Start': format_timestamp(ch['start_time']),\n",
        "            'End': format_timestamp(ch['end_time']),\n",
        "            'Duration (s)': ch['duration_seconds'],\n",
        "            'Emotion': ch['emotion']['primary_emotion'],\n",
        "            'Confidence': f\"{ch['confidence_score']:.0%}\",\n",
        "            'Words': ch['word_count']\n",
        "        } for ch in st.session_state.chapters])\n",
        "\n",
        "        st.dataframe(df, use_container_width=True)\n",
        "\n",
        "    else:\n",
        "        st.info(\"ğŸ“Œ Generate chapters first to see analysis\")\n",
        "\n",
        "# =============================\n",
        "# TAB 3: EVALUATION\n",
        "# =============================\n",
        "with tabs[2]:\n",
        "    st.header(\"Chapter Evaluation Report\")\n",
        "\n",
        "    if st.session_state.evaluation_results and 'metrics' in st.session_state.evaluation_results:\n",
        "        results = st.session_state.evaluation_results\n",
        "        metrics = results['metrics']\n",
        "\n",
        "        # Overall score\n",
        "        st.markdown(f\"### ğŸ¯ Overall Quality Score: {metrics['overall_quality_score']:.1f}/100\")\n",
        "        st.progress(metrics['overall_quality_score'] / 100)\n",
        "\n",
        "        st.markdown(\"---\")\n",
        "\n",
        "        # Summary metrics\n",
        "        col1, col2, col3, col4 = st.columns(4)\n",
        "\n",
        "        with col1:\n",
        "            st.metric(\"Official Chapters\", metrics['num_official_chapters'])\n",
        "        with col2:\n",
        "            st.metric(\"Generated Chapters\", metrics['num_generated_chapters'])\n",
        "        with col3:\n",
        "            st.metric(\"Aligned Chapters\", metrics['num_aligned_chapters'])\n",
        "        with col4:\n",
        "            st.metric(\"Match Ratio\", f\"{metrics['chapter_count_match_ratio']:.0%}\")\n",
        "\n",
        "        st.markdown(\"---\")\n",
        "\n",
        "        # Detailed metrics\n",
        "        col1, col2 = st.columns(2)\n",
        "\n",
        "        with col1:\n",
        "            st.subheader(\"â±ï¸ Timestamp Overlap\")\n",
        "            st.metric(\"Average Overlap\", f\"{metrics['avg_overlap_percentage']:.1f}%\")\n",
        "            st.metric(\"Median Overlap\", f\"{metrics['median_overlap_percentage']:.1f}%\")\n",
        "            st.metric(\"Good Overlaps (>50%)\",\n",
        "                     f\"{metrics['chapters_with_good_overlap_50plus']}/{metrics['num_aligned_chapters']}\")\n",
        "\n",
        "        with col2:\n",
        "            st.subheader(\"ğŸ“ Title Similarity\")\n",
        "            st.metric(\"Average Similarity\", f\"{metrics['avg_title_similarity']:.3f}\")\n",
        "            st.metric(\"Median Similarity\", f\"{metrics['median_title_similarity']:.3f}\")\n",
        "            st.metric(\"Good Matches (>0.5)\",\n",
        "                     f\"{metrics['chapters_with_good_title_sim_50plus']}/{metrics['num_aligned_chapters']}\")\n",
        "\n",
        "        # Visualization\n",
        "        if 'alignments' in results and results['alignments']:\n",
        "            st.markdown(\"---\")\n",
        "            charts = create_evaluation_charts(metrics, results['alignments'])\n",
        "\n",
        "            col1, col2 = st.columns(2)\n",
        "\n",
        "            with col1:\n",
        "                if 'overlap_hist' in charts:\n",
        "                    st.plotly_chart(charts['overlap_hist'], use_container_width=True)\n",
        "\n",
        "            with col2:\n",
        "                if 'similarity_bar' in charts:\n",
        "                    st.plotly_chart(charts['similarity_bar'], use_container_width=True)\n",
        "\n",
        "            # Detailed alignment table\n",
        "            st.subheader(\"ğŸ“Š Detailed Chapter Alignment\")\n",
        "\n",
        "            alignment_data = []\n",
        "            for a in results['alignments']:\n",
        "                alignment_data.append({\n",
        "                    'Gen #': a['generated_chapter_number'],\n",
        "                    'Generated Title': a['generated_title'],\n",
        "                    'Off #': a['official_chapter_number'],\n",
        "                    'Official Title': a['official_title'],\n",
        "                    'Overlap %': f\"{a['overlap_percentage']:.1f}%\",\n",
        "                    'Title Sim': f\"{a['title_similarity']['average']:.3f}\"\n",
        "                })\n",
        "\n",
        "            st.dataframe(pd.DataFrame(alignment_data), use_container_width=True)\n",
        "\n",
        "        # Download evaluation report\n",
        "        st.markdown(\"---\")\n",
        "        st.markdown(download_json(results, \"evaluation_report.json\"), unsafe_allow_html=True)\n",
        "\n",
        "    elif st.session_state.evaluation_results and 'error' in st.session_state.evaluation_results:\n",
        "        st.warning(f\"âš ï¸ {st.session_state.evaluation_results['error']}\")\n",
        "    else:\n",
        "        st.info(\"ğŸ“Œ Enable evaluation and process a video to see results\")\n",
        "\n",
        "# =============================\n",
        "# FOOTER\n",
        "# =============================\n",
        "st.markdown(\"---\")\n",
        "st.markdown(\"\"\"\n",
        "<div style='text-align: center; color: #666;'>\n",
        "    <p>ğŸ¬ <b>AI Video Chapter Generator</b> | Powered by CLIP, Whisper, BART & Emotion AI</p>\n",
        "    <p>Built with Streamlit for Kaggle Notebooks</p>\n",
        "</div>\n",
        "\"\"\", unsafe_allow_html=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLZ_FPAb0-2e",
        "outputId": "1bb9be62-ae22-485b-e03b-224e3690fcd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[90m2025-11-07T06:54:02Z\u001b[0m \u001b[32mINF\u001b[0m Initiating graceful shutdown due to signal interrupt ...\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "\u001b[90m2025-11-07T06:54:02Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m failed to run the datagram handler \u001b[31merror=\u001b[0m\u001b[31m\"context canceled\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.77\n",
            "\u001b[90m2025-11-07T06:54:02Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m failed to serve tunnel connection \u001b[31merror=\u001b[0m\u001b[31m\"accept stream listener encountered a failure while serving\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.77\n",
            "\u001b[90m2025-11-07T06:54:02Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Serve tunnel error \u001b[31merror=\u001b[0m\u001b[31m\"accept stream listener encountered a failure while serving\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.77\n",
            "\u001b[90m2025-11-07T06:54:02Z\u001b[0m \u001b[32mINF\u001b[0m Retrying connection in up to 1s \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.77\n",
            "\u001b[90m2025-11-07T06:54:02Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Connection terminated \u001b[36mconnIndex=\u001b[0m0\n",
            "\u001b[90m2025-11-07T06:54:02Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m no more connections active and exiting\n",
            "\u001b[90m2025-11-07T06:54:02Z\u001b[0m \u001b[32mINF\u001b[0m Tunnel server stopped\n",
            "\u001b[90m2025-11-07T06:54:02Z\u001b[0m \u001b[32mINF\u001b[0m Metrics server stopped\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit cloudflared\n",
        "!wget -q -O /tmp/cloudflared https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64\n",
        "!chmod +x /tmp/cloudflared\n",
        "!streamlit run streamlit_app.py --server.port 8501 --server.headless true & /tmp/cloudflared tunnel --url http://localhost:8501\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xpS3QGoZ1A3i"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}